<!doctype html>
<html class="docs-version-v0.2.2" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Colossal-AI RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Colossal-AI Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1XKZVCCKRZ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1XKZVCCKRZ",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Colossal-AI" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="https://snack.expo.io/embed.js" async></script>
<script src="https://js-eu1.hs-scripts.com/26563514.js" async defer="defer" id="hs-script-loader"></script><title data-react-helmet="true">Meet Gemini:The Heterogeneous Memory Manager of Colossal-AI | Colossal-AI</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://colossalai.org/docs/advanced_tutorials/meet_gemini"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="v0.2.2"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-v0.2.2"><meta data-react-helmet="true" property="og:title" content="Meet Gemini:The Heterogeneous Memory Manager of Colossal-AI | Colossal-AI"><meta data-react-helmet="true" name="description" content="Author: Jiarui Fang, Yang You"><meta data-react-helmet="true" property="og:description" content="Author: Jiarui Fang, Yang You"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://colossalai.org/docs/advanced_tutorials/meet_gemini"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/advanced_tutorials/meet_gemini" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/zh-Hans/docs/advanced_tutorials/meet_gemini" hreflang="zh-Hans"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/advanced_tutorials/meet_gemini" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://XP2V2KAOVI-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b5c97f7b.css">
<link rel="preload" href="/assets/js/runtime~main.b6ce1973.js" as="script">
<link rel="preload" href="/assets/js/main.aef369b8.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet"><div class="Toastify"></div><div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner InnerContainer_1wkI"><div class="navbar__items"><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--light_3UqQ"><img src="/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--dark_hz6m"></div><b class="navbar__title"> </b></a><a class="navbar__item navbar__link" href="/docs/get_started/installation">Tutorials</a><a href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Examples</a><a href="http://docs.colossalai.org" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Docs</a><a href="https://www.hpc-ai.tech/blog" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Blog</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/advanced_tutorials/add_your_parallel">v0.2.2</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_3vod"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>English</span></span></a><ul class="dropdown__menu"><li><a href="/docs/advanced_tutorials/meet_gemini" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active">English</a></li><li><a href="/zh-Hans/docs/advanced_tutorials/meet_gemini" target="_self" rel="noopener noreferrer" class="dropdown__link">ç®€ä½“ä¸­æ–‡</a></li></ul></div><div class="displayOnlyInLargeViewport_2uzv IconContainer_aWwG"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="Icon_3e04" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div><div class="toggle_71bT toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">ðŸŒœ</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">ðŸŒž</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1ZXk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="Wrapper_ReNv main-docs-wrapper"><div class="docPage_3AUJ"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_35hR" type="button"></button><main class="docMainContainer_2AUC"><div class="padding-vert--lg container docItemWrapper_1WZa"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Meet Gemini:The Heterogeneous Memory Manager of Colossal-AI</h1></header><p>Author: <a href="https://github.com/feifeibear" target="_blank" rel="noopener noreferrer">Jiarui Fang</a>, Yang You</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="brief">Brief<a class="hash-link" href="#brief" title="Direct link to heading">â€‹</a></h2><p>When you only have a few GPUs for large model training tasks, <strong>heterogeneous training</strong> is the most effective approach. By accommodating model data in CPU and GPU and moving the data to the computing device when necessary, it can breakthrough the GPU memory wall by using GPU  and CPU memory (composed of CPU DRAM or nvme SSD memory) together at the same time. Moreover, the model scale can be further improved by combining heterogeneous training with the other parallel approaches, such as data parallel, tensor parallel and pipeline parallel . We now describe the design details of <strong>Gemini</strong>, the heterogeneous memory space manager of Colossal-AI. Its idea comes from <a href="https://arxiv.org/abs/2108.05818" target="_blank" rel="noopener noreferrer">PatrickStar</a>, which has been adapted to Colossal-AI.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="usage">Usage<a class="hash-link" href="#usage" title="Direct link to heading">â€‹</a></h2><p>At present, Gemini supports compatibility with ZeRO parallel mode, and it is really simple to use Gemini. Set attribute of zero model_config, i.e., tensor_placement_policy=&#x27;auto&#x27;.</p><div class="codeBlockContainer_K1bP theme-code-block"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">zero = dict(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_config=dict(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        tensor_placement_policy=&#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        shard_strategy=BucketTensorShardStrategy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer_config=dict(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Note that Gemini and parallel strategies such as tensor parallelism, data parallelism, pipeline parallelism and zero should be decoupled. However, Colossal-AI requires users to use Gemini with ZeRO. Although they are not necessarily coupled, we will improve it in the near future.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="concepts">Concepts<a class="hash-link" href="#concepts" title="Direct link to heading">â€‹</a></h2><p><strong>OP</strong>(<strong>OP</strong>erator)ï¼šoperation of a neural network layer, such as linear, LayerNorm, etc. The operator can be a forward propagation calculation or a back-propagation calculation.</p><p>Neural networks must manage two types of training data during training.
<strong>model data</strong>: consists of parameters, gradients and optimizer states, and its scale is related to the definition of model structure.</p><p><strong>Non-model data</strong>: mainly composed of the intermediate tensor generated by the operator and the temporary variables of the operator. Non-model data changes dynamically according to the configuration of training tasks, such as batch size. Model data and non-model data compete with each other for GPU memory.</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="design-details">Design Details<a class="hash-link" href="#design-details" title="Direct link to heading">â€‹</a></h2><p>In some solutions, the <a href="https://arxiv.org/abs/2101.06840" target="_blank" rel="noopener noreferrer">Zero-offload</a> adopted by DeepSpeed statically divides model data between CPU and GPU memory, and their memory layout is constant for different training configurations. As shown on the left of the figure below, when the GPU memory is insufficient to meet its corresponding model data requirements, the system will crash even if there is still available memory on the CPU at that time. While Colossal-AI can complete the training by moving part of the model data to the CPU.</p><figure style="text-align:center"><img src="https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/tutorial/gemini/deepspeed_compare.png"><figcaption>Comparison of the memory management of Zero-Offload and Gemini</figcaption></figure><p>Colossal-AI designed Gemini, just like two-stars, which manages the memory space of CPU and GPU efficiently. It can make the tensor dynamically distributed in the storage space of CPU-GPU during training, so that the model training can break through the memory wall of GPU. The memory manager consists of two parts: <strong>MemStatsCollector (MSC)</strong> and <strong>StatefuleTensorMgr (STM)</strong>.</p><p>We take advantage of the iterative characteristics of the deep learning network training process. We divide iterations into two stages: warmup and non-warmup. One or several iterative steps at the beginning belong to the warmup stage, and the other iterative steps belong to the non-warmup stage. In the warmup stage, we collect information for the MSC, while in the non-warmup stage, STM gets the information collected by the MSC to move the tensor, so as to minimize the CPU-GPU data movement volume.</p><figure style="text-align:center"><img src="https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/tutorial/gemini/gemini_workflow.png"><figcaption>The workflow of Gemini during warmup and non-warmup phase</figcaption></figure><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="statefultensormgr">StatefulTensorMgr<a class="hash-link" href="#statefultensormgr" title="Direct link to heading">â€‹</a></h3><p>STM manages the information of all model data tensors. In the process of model construction, Colossal-AI registers all model data tensors with STM. The memory manager marks each tensor with state information. The state set includes three types: HOLD, COMPUTE and FREE. The functions of STM are as follows:</p><p><strong>Query memory usage:</strong>by traversing the locations of all tensors in heterogeneous space, obtain the memory occupation of CPU and GPU by model data.</p><p><strong>Transition tensor state:</strong> it marks the tensor as COMPUTE state before each model data tensor participates in the operator calculation, and as HOLD state after calculation. The FREE state marked if the tensor is no longer in use.</p><p><strong>Adjust tensor position:</strong>tensor manager ensures that the tensor in COMPUTE state is placed on the computing device. If the storage space of the computing device is insufficient, it is necessary to move some tensors in HOLD state to other devices for storage. Tensor eviction strategy requires information from MSC, which will be introduced later.</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="memstatscollector">MemStatsCollector<a class="hash-link" href="#memstatscollector" title="Direct link to heading">â€‹</a></h3><p>In the warmup stage, the memory information statistician monitors the memory usage of model data and non-model data in CPU and GPU for reference in the non-warmup stage. We can obtain the memory usage of model data at a certain time by querying STM. However, the memory usage of non-model data is difficult to obtain. Owing to the life cycle of non-model data not being managed by users, the existing deep learning framework does not expose the tracking interface of non-model data to users. MSC obtains the usage of CPU and GPU memory by non-model in the warmup stage through sampling. The specific methods are as follows:</p><p>We trigger the memory sampling operation at the beginning and end of the operator. We call this time point <strong>sampling moment</strong>, and the time between the two sampling moments is called <strong>period</strong>. The calculation process is a black box. Due to the possible allocation of temporary buffer, the memory usage is very complex. However, we can accurately obtain the maximum memory usage of the system during the period. The use of non-model data can be obtained by the maximum memory use of the system between two statistical moments-model memory use.</p><p>How do we design the sampling time. Before we choose model data layout adjust of preOp. As shown in the figure below. We sample the system memory used of the previous period and the model data memory used of the next period. The parallel strategy will cause obstacles to the work of MSC. As shown in the figure, for example, for ZeRO or Tensor Parallel, because gathering model data is required before OP calculation, it will bring additional memory requirements. Therefore, we require to sample the system memory before the model data changes, so that the MSC will capture the model change memory of preOp within a period. For example, in period 2-3, we consider the memory changes brought by tensor gather and shard.</p><p>Although the sampling time can be placed in other locations, such as excluding the new information of the change of the gather buffer, it will cause trouble. There are differences in the implementation of Op in different parallel modes. For example, for Linear Op, gather buffer in Tensor Parallel is allocated in Op. For ZeRO, the allocation of gather buffer is in PreOp. Sampling at the beginning of PreOp helps to unify the two situations.</p><figure style="text-align:center"><img src="https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/tutorial/gemini/gemini_mem_curve.png"><figcaption>workflow</figcaption></figure><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="tensor-eviction-strategy">Tensor Eviction Strategy<a class="hash-link" href="#tensor-eviction-strategy" title="Direct link to heading">â€‹</a></h3><p>The important duty of MSC is to adjust the tensor layout position. For example, at S2 in the figure above, we reduce the model data on the device, and meet the peak memory requirement calculated in period 2-3.</p><p>In the warmup stage, since we haven&#x27;t finished a complete iteration yet, we don&#x27;t know actual memory occupation. At this time, we limit the upper bound of memory usage of the model data. For example, only 30% of the GPU memory can be used. This ensures that we can successfully complete the warmup state.</p><p>In the non-warmup stage, we need to use the memory information of non-model data collected in the warm-up stage to reserve the peak memory required by the computing device for the next Period, which requires us to move some model tensors. In order to avoid frequent replacement of the same tensor in and out of the CPU-GPU, causing a phenomenon similar to <a href="https://en.wikipedia.org/wiki/Thrashing_(computer_science)" target="_blank" rel="noopener noreferrer">cache thrashing</a>. Using the iterative characteristics of DNN training, we design the OPT cache swap out strategy. Specifically, in the warmup stage, we record the sampling time required by each tensor computing device. If we need to expel some HOLD tensors, we will choose the latest tensor needed on this device as the victim.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#brief" class="table-of-contents__link toc-highlight">Brief</a></li><li><a href="#usage" class="table-of-contents__link toc-highlight">Usage</a></li><li><a href="#concepts" class="table-of-contents__link toc-highlight">Concepts</a></li><li><a href="#design-details" class="table-of-contents__link toc-highlight">Design Details</a><ul><li><a href="#statefultensormgr" class="table-of-contents__link toc-highlight">StatefulTensorMgr</a></li><li><a href="#memstatscollector" class="table-of-contents__link toc-highlight">MemStatsCollector</a></li><li><a href="#tensor-eviction-strategy" class="table-of-contents__link toc-highlight">Tensor Eviction Strategy</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer Container_ZO7N"><div class="InnerContainer_kEOB"><div class="ContentContainer_Bd2W"><div class="FooterLeft_UU7Q"><div class="BrandContainer_37NB"><img class="BrandImage_1lbV" alt="AgileTs Logo" height="30" src="/img/logo.svg"></div><div class="Tagline_2AGk">An integrated large-scale model training system with efficient parallelization techniques.</div><button class="ButtonContainer_oPl2 GithubButton_1Y3L"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="GithubIcon_3htU" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><div>GITHUB</div></button></div><div class="FooterRight_1NHD"><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">Resources</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="/docs/get_started/installation" label="Tutorials" to="docs/get_started/installation">Tutorials</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="http://docs.colossalai.org" label="API Docs" to="http://docs.colossalai.org">API Docs</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" label="Examples" to="https://github.com/hpcaitech/ColossalAI/tree/main/examples">Examples</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/discussions" label="Forum" to="https://github.com/hpcaitech/ColossalAI/discussions">Forum</a></ul></div><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">Community</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI" rel="noopener noreferrer" target="_blank" label="GitHub">GitHub</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://www.hpc-ai.tech/blog" rel="noopener noreferrer" target="_blank" label="Blog">Blog</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://twitter.com/HPCAITech" rel="noopener noreferrer" target="_blank" label="Twitter">Twitter</a></ul></div></div></div><div class="BottomContainer_1let"><div class="CopyrightText_25Fq">Copyright Â© 2023 All Rights Reserved by HPC-AI Technology Inc.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.b6ce1973.js"></script>
<script src="/assets/js/main.aef369b8.js"></script>
</body>
</html>