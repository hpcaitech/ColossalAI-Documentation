"use strict";(self.webpackChunkagile_docs=self.webpackChunkagile_docs||[]).push([[4024],{3905:function(e,n,a){a.d(n,{Zo:function(){return d},kt:function(){return m}});var t=a(7294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function l(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function i(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?l(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},l=Object.keys(e);for(t=0;t<l.length;t++)a=l[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(t=0;t<l.length;t++)a=l[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=t.createContext({}),p=function(e){var n=t.useContext(s),a=n;return e&&(a="function"==typeof e?e(n):i(i({},n),e)),a},d=function(e){var n=p(e.components);return t.createElement(s.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},_=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),_=p(a),m=r,u=_["".concat(s,".").concat(m)]||_[m]||c[m]||l;return a?t.createElement(u,i(i({ref:n},d),{},{components:a})):t.createElement(u,i({ref:n},d))}));function m(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=_;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=a[p];return t.createElement.apply(null,i)}return t.createElement.apply(null,a)}_.displayName="MDXCreateElement"},7036:function(e,n,a){a.r(n),a.d(n,{frontMatter:function(){return o},contentTitle:function(){return s},metadata:function(){return p},toc:function(){return d},default:function(){return _}});var t=a(3117),r=a(102),l=(a(7294),a(3905)),i=["components"],o={},s="\u4f7f\u7528 Colossal-AI \uff08\u4ece\u6570\u636e\u5e76\u884c\u5230\u5f02\u6784\u5e76\u884c\uff09\u52a0\u901f ViT \u8bad\u7ec3\u8be6\u89e3",p={unversionedId:"advanced_tutorials/train_vit_with_hybrid_parallelism",id:"version-v0.2.2/advanced_tutorials/train_vit_with_hybrid_parallelism",title:"\u4f7f\u7528 Colossal-AI \uff08\u4ece\u6570\u636e\u5e76\u884c\u5230\u5f02\u6784\u5e76\u884c\uff09\u52a0\u901f ViT \u8bad\u7ec3\u8be6\u89e3",description:"\u4f5c\u8005\uff1aYuxuan Lou",source:"@site/i18n/zh-Hans/docusaurus-plugin-content-docs/version-v0.2.2/advanced_tutorials/train_vit_with_hybrid_parallelism.md",sourceDirName:"advanced_tutorials",slug:"/advanced_tutorials/train_vit_with_hybrid_parallelism",permalink:"/zh-Hans/docs/advanced_tutorials/train_vit_with_hybrid_parallelism",tags:[],version:"v0.2.2",frontMatter:{}},d=[{value:"\u5f15\u8a00",id:"\u5f15\u8a00",children:[],level:2},{value:"\u76ee\u5f55",id:"\u76ee\u5f55",children:[],level:2},{value:"Colossal-AI \u5b89\u88c5",id:"colossal-ai-\u5b89\u88c5",children:[],level:2},{value:"\u6570\u636e\u5e76\u884c",id:"\u6570\u636e\u5e76\u884c",children:[{value:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6 (<code>data_parallel/config.py</code>)",id:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6-data_parallelconfigpy",children:[],level:3},{value:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c (<code>/data_parallel/train_with_cifar10.py</code>)",id:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c-data_paralleltrain_with_cifar10py",children:[{value:"\u5bfc\u5165\u6a21\u5757",id:"\u5bfc\u5165\u6a21\u5757",children:[],level:4},{value:"\u542f\u52a8 Colossal-AI",id:"\u542f\u52a8-colossal-ai",children:[],level:4},{value:"\u6784\u5efa\u6a21\u578b",id:"\u6784\u5efa\u6a21\u578b",children:[],level:4},{value:"\u6784\u5efa CIFAR-10 \u6570\u636e\u52a0\u8f7d\u5668",id:"\u6784\u5efa-cifar-10-\u6570\u636e\u52a0\u8f7d\u5668",children:[],level:4},{value:"\u5b9a\u4e49\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668",id:"\u5b9a\u4e49\u4f18\u5316\u5668\u635f\u5931\u51fd\u6570\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668",children:[],level:4},{value:"\u542f\u52a8\u7528\u4e8e\u8bad\u7ec3\u7684 Colossal-AI \u5f15\u64ce",id:"\u542f\u52a8\u7528\u4e8e\u8bad\u7ec3\u7684-colossal-ai-\u5f15\u64ce",children:[],level:4},{value:"\u8bad\u7ec3\uff1aTrainer \u5e94\u7528\u7a0b\u5e8f\u7f16\u7a0b\u63a5\u53e3",id:"\u8bad\u7ec3trainer-\u5e94\u7528\u7a0b\u5e8f\u7f16\u7a0b\u63a5\u53e3",children:[],level:4}],level:3},{value:"\u5f00\u59cb\u8bad\u7ec3",id:"\u5f00\u59cb\u8bad\u7ec3",children:[],level:3}],level:2},{value:"\u6d41\u6c34\u7ebf\u5e76\u884c",id:"\u6d41\u6c34\u7ebf\u5e76\u884c",children:[{value:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6(<code>hybrid_parallel/configs/vit_pipeline.py</code>)",id:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6hybrid_parallelconfigsvit_pipelinepy",children:[],level:3},{value:"\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b (<code>/hybrid_parallel/model/vit.py</code>)",id:"\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b-hybrid_parallelmodelvitpy",children:[],level:3},{value:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c (<code>/hybrid_parallel/train_with_cifar10.py</code>)",id:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c-hybrid_paralleltrain_with_cifar10py",children:[{value:"\u5bfc\u5165\u6a21\u5757",id:"\u5bfc\u5165\u6a21\u5757-1",children:[],level:4},{value:"\u542f\u52a8 Colossal-AI",id:"\u542f\u52a8-colossal-ai-1",children:[],level:4},{value:"\u5b9a\u4e49\u6a21\u578b",id:"\u5b9a\u4e49\u6a21\u578b",children:[],level:4},{value:"\u8ba1\u7b97\u53c2\u6570\u4e2a\u6570",id:"\u8ba1\u7b97\u53c2\u6570\u4e2a\u6570",children:[],level:4},{value:"\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u4f18\u5316\u5668\u7b49\u7ec4\u4ef6",id:"\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668\u4f18\u5316\u5668\u7b49\u7ec4\u4ef6",children:[],level:4},{value:"\u542f\u52a8 Colossal-AI \u5f15\u64ce",id:"\u542f\u52a8-colossal-ai-\u5f15\u64ce",children:[],level:4},{value:"\u8bad\u7ec3\uff1a\u57fa\u4e8eengine",id:"\u8bad\u7ec3\u57fa\u4e8eengine",children:[],level:4}],level:3},{value:"\u5f00\u59cb\u8bad\u7ec3",id:"\u5f00\u59cb\u8bad\u7ec3-1",children:[],level:3}],level:2},{value:"\u5f20\u91cf\u5e76\u884c\u548c\u5f02\u6784\u5e76\u884c",id:"\u5f20\u91cf\u5e76\u884c\u548c\u5f02\u6784\u5e76\u884c",children:[{value:"\u6784\u9020\u60a8\u7684\u914d\u7f6e\u6587\u4ef6 (<code>/hybrid_parallel/configs/vit_1d_tp2_pp2.py</code>)",id:"\u6784\u9020\u60a8\u7684\u914d\u7f6e\u6587\u4ef6-hybrid_parallelconfigsvit_1d_tp2_pp2py",children:[],level:3},{value:"\u5f00\u59cb\u8bad\u7ec3",id:"\u5f00\u59cb\u8bad\u7ec3-2",children:[],level:3}],level:2}],c={toc:d};function _(e){var n=e.components,a=(0,r.Z)(e,i);return(0,l.kt)("wrapper",(0,t.Z)({},c,a,{components:n,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"\u4f7f\u7528-colossal-ai-\u4ece\u6570\u636e\u5e76\u884c\u5230\u5f02\u6784\u5e76\u884c\u52a0\u901f-vit-\u8bad\u7ec3\u8be6\u89e3"},"\u4f7f\u7528 Colossal-AI \uff08\u4ece\u6570\u636e\u5e76\u884c\u5230\u5f02\u6784\u5e76\u884c\uff09\u52a0\u901f ViT \u8bad\u7ec3\u8be6\u89e3"),(0,l.kt)("p",null,"\u4f5c\u8005\uff1aYuxuan Lou"),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"\u793a\u4f8b\u4ee3\u7801")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://github.com/hpcaitech/ColossalAI-Examples/tree/main/image/vision_transformer"},"Colossal-AI Examples ViT on Cifar10"))),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"\u76f8\u5173\u6587\u732e")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2010.11929.pdf"},"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"))),(0,l.kt)("h2",{id:"\u5f15\u8a00"},"\u5f15\u8a00"),(0,l.kt)("p",null,"\u5728\u8fd9\u4e2aViT\u6a21\u578b\u7684\u6837\u4f8b\u4e2d\uff0cColossal-AI \u63d0\u4f9b\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5e76\u884c\u6280\u672f\u6765\u52a0\u901f\u6a21\u578b\u8bad\u7ec3\uff1a\u6570\u636e\u5e76\u884c\uff0c\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u5f20\u91cf\u5e76\u884c\u3002\u6211\u4eec\u5c06\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u8fd9\u4e09\u79cd\u5e76\u884c\u6280\u672f\u5728 CIFAR-10 \u6570\u636e\u96c6\u4e0a\u8bad\u7ec3 ViT\u3002\u4e3a\u4e86\u8fd0\u884c\u9879\u76ee\uff0c\u9700\u89812-4\u4e2a GPU\u3002"),(0,l.kt)("h2",{id:"\u76ee\u5f55"},"\u76ee\u5f55"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Colossal-AI \u5b89\u88c5\u65b9\u6cd5"),(0,l.kt)("li",{parentName:"ol"},"\u4f7f\u7528\u6570\u636e\u5e76\u884c\u8bad\u7ec3 ViT \u6b65\u9aa4"),(0,l.kt)("li",{parentName:"ol"},"\u4f7f\u7528\u6570\u636e\u6d41\u6c34\u7ebf\u5e76\u884c\u8bad\u7ec3 ViT \u6b65\u9aa4"),(0,l.kt)("li",{parentName:"ol"},"\u4f7f\u7528\u5f20\u91cf\u5e76\u884c\u6216\u5f02\u6784\u5e76\u884c\u8bad\u7ec3 ViT \u6b65\u9aa4")),(0,l.kt)("h2",{id:"colossal-ai-\u5b89\u88c5"},"Colossal-AI \u5b89\u88c5"),(0,l.kt)("p",null,"\u53ef\u4ee5\u901a\u8fc7 Python \u7684\u5b98\u65b9\u7d22\u5f15\u6765\u5b89\u88c5 Colossal-AI \u8f6f\u4ef6\u5305\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"pip install colossalai\n")),(0,l.kt)("h2",{id:"\u6570\u636e\u5e76\u884c"},"\u6570\u636e\u5e76\u884c"),(0,l.kt)("p",null,"\u6570\u636e\u5e76\u884c\u662f\u5b9e\u73b0\u52a0\u901f\u6a21\u578b\u8bad\u7ec3\u7684\u57fa\u672c\u65b9\u6cd5\u3002\u901a\u8fc7\u4e24\u6b65\u53ef\u4ee5\u5b9e\u73b0\u8bad\u7ec3\u7684\u6570\u636e\u5e76\u884c\uff1a"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"\u6784\u5efa\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6"),(0,l.kt)("li",{parentName:"ol"},"\u5728\u8bad\u7ec3\u811a\u672c\u4e2d\u4fee\u6539\u5f88\u5c11\u7684\u51e0\u884c\u4ee3\u7801")),(0,l.kt)("h3",{id:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6-data_parallelconfigpy"},"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6 (",(0,l.kt)("inlineCode",{parentName:"h3"},"data_parallel/config.py"),")"),(0,l.kt)("p",null,"\u4e3a\u4e86\u4f7f\u7528 Colossal-AI\uff0c\u7b2c\u4e00\u6b65\u662f\u6784\u5efa\u914d\u7f6e\u6587\u4ef6\u3002\u5e76\u4e14\uff0c\u5728\u8fd9\u91cc\u6709\u4e24\u79cd\u53d8\u91cf\uff1a"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Colossal-AI \u529f\u80fd\u914d\u7f6e"))),(0,l.kt)("p",null,"Colossal-AI \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u7684\u529f\u80fd\u6765\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\uff08\u5305\u62ec\u6a21\u578b\u5e76\u884c\uff0c\u6df7\u5408\u7cbe\u5ea6\uff0c\u96f6\u5197\u4f59\u4f18\u5316\u5668\u7b49\uff09\u3002\u6bcf\u4e2a\u529f\u80fd\u90fd\u662f\u7531\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u76f8\u5e94\u5b57\u6bb5\u5b9a\u4e49\u7684\u3002\u5982\u679c\u6211\u4eec\u53ea\u7528\u5230\u6570\u636e\u5e76\u884c\uff0c\u90a3\u4e48\u6211\u4eec\u53ea\u9700\u8981\u5177\u4f53\u8bf4\u660e\u5e76\u884c\u6a21\u5f0f\u3002\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528 PyTorch \u6700\u521d\u63d0\u51fa\u7684\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u5b9a\u4e49\u6df7\u5408\u7cbe\u5ea6\u914d\u7f6e ",(0,l.kt)("inlineCode",{parentName:"p"},"fp16 = dict(mode=AMP_TYPE.TORCH)")," \u3002"),(0,l.kt)("ol",{start:2},(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"\u5168\u5c40\u8d85\u53c2\u6570"))),(0,l.kt)("p",null,"\u5168\u5c40\u8d85\u53c2\u6570\u5305\u62ec\u7279\u5b9a\u4e8e\u6a21\u578b\u7684\u8d85\u53c2\u6570\u3001\u8bad\u7ec3\u8bbe\u7f6e\u3001\u6570\u636e\u96c6\u4fe1\u606f\u7b49\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.amp import AMP_TYPE\n# ViT Base\nBATCH_SIZE = 256\nDROP_RATE = 0.1\nNUM_EPOCHS = 300\n# mix precision\nfp16 = dict(\n    mode=AMP_TYPE.TORCH,\n)\ngradient_accumulation = 16\nclip_grad_norm = 1.0\ndali = dict(\n    gpu_aug=True,\n    mixup_alpha=0.2\n)\n")),(0,l.kt)("h3",{id:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c-data_paralleltrain_with_cifar10py"},"\u4fee\u6539\u8bad\u7ec3\u811a\u672c (",(0,l.kt)("inlineCode",{parentName:"h3"},"/data_parallel/train_with_cifar10.py"),")"),(0,l.kt)("h4",{id:"\u5bfc\u5165\u6a21\u5757"},"\u5bfc\u5165\u6a21\u5757"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Colossal-AI \u76f8\u5173\u6a21\u5757")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import colossalai\nfrom colossalai.context import ParallelMode\nfrom colossalai.core import global_context as gpc\nfrom colossalai.logging import disable_existing_loggers, get_dist_logger\nfrom colossalai.nn.lr_scheduler import LinearWarmupLR\nfrom colossalai.nn.metric import Accuracy\nfrom colossalai.trainer import Trainer, hooks\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"\u5176\u4ed6\u6a21\u5757")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import os\nimport torch\nfrom timm.models import vit_base_patch16_224\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\n")),(0,l.kt)("h4",{id:"\u542f\u52a8-colossal-ai"},"\u542f\u52a8 Colossal-AI"),(0,l.kt)("p",null,"\u5728\u8bad\u7ec3\u811a\u672c\u4e2d\uff0c\u5728\u6784\u5efa\u597d\u914d\u7f6e\u6587\u4ef6\u540e\uff0c\u9700\u8981\u4e3a Colossal-AI \u521d\u59cb\u5316\u5206\u5e03\u5f0f\u73af\u5883\u3002\u6211\u4eec\u5c06\u6b64\u8fc7\u7a0b\u79f0\u4e3a ",(0,l.kt)("inlineCode",{parentName:"p"},"launch")," \u3002\u5728 Colossal-AI \u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u51e0\u79cd\u542f\u52a8\u65b9\u6cd5\u6765\u521d\u59cb\u5316\u5206\u5e03\u5f0f\u540e\u7aef\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528 ",(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.launch")," \u548c ",(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.get_default_parser ")," \u6765\u5b9e\u73b0\u4f7f\u7528\u547d\u4ee4\u884c\u4f20\u9012\u53c2\u6570\u3002\u6b64\u5916\uff0cColossal-AI \u53ef\u4ee5\u5229\u7528 PyTorch \u63d0\u4f9b\u7684\u73b0\u6709\u542f\u52a8\u5de5\u5177\uff0c\u6b63\u5982\u8bb8\u591a\u7528\u6237\u901a\u8fc7\u4f7f\u7528\u719f\u77e5\u7684 ",(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.launch_from_torch")," \u90a3\u6837\u3002\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u60a8\u53ef\u4ee5\u67e5\u770b\u76f8\u5173",(0,l.kt)("a",{parentName:"p",href:"https://www.colossalai.org/docs/basics/launch_colossalai"},"\u6587\u6863"),"\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# initialize distributed setting\nparser = colossalai.get_default_parser()\nargs = parser.parse_args()\ncolossalai.launch_from_torch(config=args.config)\ndisable_existing_loggers()\nlogger = get_dist_logger()\n")),(0,l.kt)("p",null,"\u521d\u59cb\u5316\u540e\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528 ",(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.core.global_context")," \u8bbf\u95ee\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u53d8\u91cf\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"#access parameters\nprint(gpc.config.BATCH_SIZE)\n")),(0,l.kt)("h4",{id:"\u6784\u5efa\u6a21\u578b"},"\u6784\u5efa\u6a21\u578b"),(0,l.kt)("p",null,"\u5982\u679c\u53ea\u9700\u8981\u6570\u636e\u5e76\u884c\u6027\uff0c\u5219\u65e0\u9700\u5bf9\u6a21\u578b\u4ee3\u7801\u8fdb\u884c\u4efb\u4f55\u66f4\u6539\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528 ",(0,l.kt)("inlineCode",{parentName:"p"},"timm")," \u4e2d\u7684 ",(0,l.kt)("inlineCode",{parentName:"p"},"vit_base_patch16_224"),"\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# build model\nmodel = vit_base_patch16_224(drop_rate=0.1, num_classes=gpc.config.NUM_CLASSES)\n")),(0,l.kt)("h4",{id:"\u6784\u5efa-cifar-10-\u6570\u636e\u52a0\u8f7d\u5668"},"\u6784\u5efa CIFAR-10 \u6570\u636e\u52a0\u8f7d\u5668"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.utils.get_dataloader")," \u53ef\u4ee5\u5e2e\u52a9\u60a8\u8f7b\u677e\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def build_cifar(batch_size):\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(224, pad_if_needed=True),\n        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    transform_test = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    train_dataset = CIFAR10(root=os.environ['DATA'], train=True, download=True, transform=transform_train)\n    test_dataset = CIFAR10(root=os.environ['DATA'], train=False, transform=transform_test)\n    train_dataloader = get_dataloader(dataset=train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n    test_dataloader = get_dataloader(dataset=test_dataset, batch_size=batch_size, pin_memory=True)\n    return train_dataloader, test_dataloader\n# build dataloader\ntrain_dataloader, test_dataloader = build_cifar(gpc.config.BATCH_SIZE)\n")),(0,l.kt)("h4",{id:"\u5b9a\u4e49\u4f18\u5316\u5668\u635f\u5931\u51fd\u6570\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668"},"\u5b9a\u4e49\u4f18\u5316\u5668\uff0c\u635f\u5931\u51fd\u6570\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668"),(0,l.kt)("p",null,"Colossal-AI \u63d0\u4f9b\u4e86\u81ea\u5df1\u7684\u4f18\u5316\u5668\u3001\u635f\u5931\u51fd\u6570\u548c\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u3002PyTorch \u7684\u8fd9\u4e9b\u7ec4\u4ef6\u4e0eColossal-AI\u4e5f\u517c\u5bb9\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# build optimizer\noptimizer = colossalai.nn.Lamb(model.parameters(), lr=1.8e-2, weight_decay=0.1)\n# build loss\ncriterion = torch.nn.CrossEntropyLoss()\n# lr_scheduelr\nlr_scheduler = LinearWarmupLR(optimizer, warmup_steps=50, total_steps=gpc.config.NUM_EPOCHS)\n")),(0,l.kt)("h4",{id:"\u542f\u52a8\u7528\u4e8e\u8bad\u7ec3\u7684-colossal-ai-\u5f15\u64ce"},"\u542f\u52a8\u7528\u4e8e\u8bad\u7ec3\u7684 Colossal-AI \u5f15\u64ce"),(0,l.kt)("p",null,"Engine \u672c\u8d28\u4e0a\u662f\u5bf9\u6a21\u578b\u3001\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\u7684\u5c01\u88c5\u7c7b\u3002\u5f53\u6211\u4eec\u4f7f\u7528 ",(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.initialize")," \uff0c\u5c06\u8fd4\u56de\u4e00\u4e2a engine \u5bf9\u8c61\uff0c\u5e76\u4e14\u5b83\u5df2\u7ecf\u6309\u7167\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u6307\u5b9a\u5185\u5bb9\uff0c\u914d\u7f6e\u4e86\u68af\u5ea6\u526a\u88c1\u3001\u68af\u5ea6\u7d2f\u79ef\u548c\u96f6\u5197\u4f59\u4f18\u5316\u5668\u7b49\u529f\u80fd\u3002\u4e4b\u540e\uff0c\u57fa\u4e8e Colossal-AI \u7684 engine \u6211\u4eec\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"engine, train_dataloader, test_dataloader, _ = colossalai.initialize(\n        model, optimizer, criterion, train_dataloader, test_dataloader\n    )\n")),(0,l.kt)("h4",{id:"\u8bad\u7ec3trainer-\u5e94\u7528\u7a0b\u5e8f\u7f16\u7a0b\u63a5\u53e3"},"\u8bad\u7ec3\uff1aTrainer \u5e94\u7528\u7a0b\u5e8f\u7f16\u7a0b\u63a5\u53e3"),(0,l.kt)("p",null,"Trainer \u662f\u4e00\u4e2a\u66f4\u9ad8\u7ea7\u7684\u5c01\u88c5\u7c7b\uff0c\u7528\u6237\u53ef\u4ee5\u7528\u66f4\u5c11\u7684\u4ee3\u7801\u5c31\u53ef\u4ee5\u5b9e\u73b0\u8bad\u7ec3\u3002\u901a\u8fc7\u4f20\u9012 engine \u5bf9\u8c61\u5f88\u5bb9\u6613\u521b\u5efa trainer \u5bf9\u8c61\u3002"),(0,l.kt)("p",null,"\u6b64\u5916\uff0c\u5728 trainer \u4e2d\uff0c\u7528\u6237\u53ef\u4ee5\u81ea\u5b9a\u4e49\u4e00\u4e9b\u6302\u94a9\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6302\u94a9\u8fde\u63a5\u5230 trainer \u5bf9\u8c61\u3002\u94a9\u5b50\u5bf9\u8c61\u5c06\u6839\u636e\u8bad\u7ec3\u65b9\u6848\u5b9a\u671f\u6267\u884c\u751f\u547d\u5468\u671f\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c",(0,l.kt)("inlineCode",{parentName:"p"},"LRSchedulerHook")," \u5c06\u6267\u884c",(0,l.kt)("inlineCode",{parentName:"p"},"lr_scheduler.step()")," \u5728 ",(0,l.kt)("inlineCode",{parentName:"p"},"after_train_iter")," \u6216 ",(0,l.kt)("inlineCode",{parentName:"p"},"after_train_epoch")," \u9636\u6bb5\u66f4\u65b0\u6a21\u578b\u7684\u5b66\u4e60\u901f\u7387\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# build trainer\ntrainer = Trainer(engine=engine, logger=logger)\n# build hooks\nhook_list = [\n    hooks.LossHook(),\n    hooks.AccuracyHook(accuracy_func=MixupAccuracy()),\n    hooks.LogMetricByEpochHook(logger),\n    hooks.LRSchedulerHook(lr_scheduler, by_epoch=True),\n    # comment if you do not need to use the hooks below\n    hooks.SaveCheckpointHook(interval=1, checkpoint_dir='./ckpt'),\n    hooks.TensorboardHook(log_dir='./tb_logs', ranks=[0]),\n]\n")),(0,l.kt)("p",null,"\u4f7f\u7528 ",(0,l.kt)("inlineCode",{parentName:"p"},"trainer.fit")," \u8fdb\u884c\u8bad\u7ec3:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# start training\ntrainer.fit(\n    train_dataloader=train_dataloader,\n    test_dataloader=test_dataloader,\n    epochs=gpc.config.NUM_EPOCHS,\n    hooks=hook_list,\n    display_progress=True,\n    test_interval=1\n)\n")),(0,l.kt)("h3",{id:"\u5f00\u59cb\u8bad\u7ec3"},"\u5f00\u59cb\u8bad\u7ec3"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"DATA")," \u662f\u81ea\u52a8\u4e0b\u8f7d\u548c\u5b58\u50a8 CIFAR-10 \u6570\u636e\u96c6\u7684\u6587\u4ef6\u8def\u5f84\u3002"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"<NUM_GPUs>")," \u662f\u8981\u7528\u4e8e\u4f7f\u7528 CIFAR-10 \u6570\u636e\u96c6\uff0c\u4ee5\u6570\u636e\u5e76\u884c\u65b9\u5f0f\u8bad\u7ec3 ViT \u7684 GPU \u6570\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"export DATA=<path_to_data>\n# If your torch >= 1.10.0\ntorchrun --standalone --nproc_per_node <NUM_GPUs>  train_dp.py --config ./configs/config_data_parallel.py\n# If your torch >= 1.9.0\n# python -m torch.distributed.run --standalone --nproc_per_node= <NUM_GPUs> train_dp.py --config ./configs/config_data_parallel.py\n# Otherwise\n# python -m torch.distributed.launch --nproc_per_node <NUM_GPUs> --master_addr <node_name> --master_port 29500 train_dp.py --config ./configs/config.py\n")),(0,l.kt)("h2",{id:"\u6d41\u6c34\u7ebf\u5e76\u884c"},"\u6d41\u6c34\u7ebf\u5e76\u884c"),(0,l.kt)("p",null,"\u9664\u4e86\u6570\u636e\u5e76\u884c\u6027\uff0cColossal-AI \u8fd8\u652f\u6301\u6d41\u6c34\u7ebf\u5e76\u884c\u3002\u5177\u4f53\u800c\u8a00\uff0cColossal-AI \u4f7f\u7528 NVIDIA \u5f15\u5165\u7684 1F1B \u6d41\u6c34\u7ebf\u3002\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u60a8\u53ef\u4ee5\u67e5\u770b\u76f8\u5173",(0,l.kt)("a",{parentName:"p",href:"https://www.colossalai.org/tutorials/features/pipeline_parallel"},"\u6587\u6863"),"\u3002"),(0,l.kt)("h3",{id:"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6hybrid_parallelconfigsvit_pipelinepy"},"\u6784\u5efa\u914d\u7f6e\u6587\u4ef6(",(0,l.kt)("inlineCode",{parentName:"h3"},"hybrid_parallel/configs/vit_pipeline.py"),")"),(0,l.kt)("p",null,"\u8981\u5728\u6570\u636e\u5e76\u884c\u7684\u57fa\u7840\u4e0a\u5e94\u7528\u6d41\u6c34\u7ebf\u5e76\u884c\uff0c\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a ",(0,l.kt)("strong",{parentName:"p"},"parallel dict")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.amp import AMP_TYPE\nparallel = dict(\n    pipeline=2\n)\n# pipeline config\nNUM_MICRO_BATCHES = parallel['pipeline']\nTENSOR_SHAPE = (BATCH_SIZE // NUM_MICRO_BATCHES, SEQ_LENGTH, HIDDEN_SIZE)\nfp16 = dict(mode=AMP_TYPE.NAIVE)\nclip_grad_norm = 1.0\n")),(0,l.kt)("p",null,"\u5176\u4ed6\u914d\u7f6e\uff1a"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# hyperparameters\n# BATCH_SIZE is as per GPU\n# global batch size = BATCH_SIZE x data parallel size\nBATCH_SIZE = 256\nLEARNING_RATE = 3e-3\nWEIGHT_DECAY = 0.3\nNUM_EPOCHS = 300\nWARMUP_EPOCHS = 32\n# model config\nIMG_SIZE = 224\nPATCH_SIZE = 16\nHIDDEN_SIZE = 768\nDEPTH = 12\nNUM_HEADS = 12\nMLP_RATIO = 4\nNUM_CLASSES = 10\nCHECKPOINT = True\nSEQ_LENGTH = (IMG_SIZE // PATCH_SIZE) ** 2 + 1  # add 1 for cls token\n")),(0,l.kt)("h3",{id:"\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b-hybrid_parallelmodelvitpy"},"\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b (",(0,l.kt)("inlineCode",{parentName:"h3"},"/hybrid_parallel/model/vit.py"),")"),(0,l.kt)("p",null,"Colossal-AI \u63d0\u4f9b\u4e86\u4e24\u79cd\u4ece\u73b0\u6709\u6a21\u578b\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b\u7684\u65b9\u6cd5\u3002"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"colossalai.builder.build_pipeline_model_from_cfg")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"colossalai.builder.build_pipeline_model"))),(0,l.kt)("p",null,"\u6b64\u5916\uff0c\u60a8\u8fd8\u53ef\u4ee5\u4f7f\u7528 Colossal-AI \u4ece\u5934\u5f00\u59cb\u6784\u5efa\u6d41\u6c34\u7ebf\u6a21\u578b\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import math\nfrom typing import Callable\nimport inspect\nimport torch\nfrom colossalai import nn as col_nn\nfrom colossalai.registry import LAYERS, MODELS\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.core import global_context as gpc\nfrom colossalai.context import ParallelMode\nfrom colossalai.builder.pipeline import partition_uniform\nfrom torch import dtype, nn\nfrom model_zoo.vit.vit import ViTBlock, ViTEmbedding, ViTHead\n@MODELS.register_module\nclass PipelineVisionTransformer(nn.Module):\n    def __init__(self,\n                 img_size: int = 224,\n                 patch_size: int = 16,\n                 in_chans: int = 3,\n                 num_classes: int = 1000,\n                 depth: int = 12,\n                 num_heads: int = 12,\n                 dim: int = 768,\n                 mlp_ratio: int = 4,\n                 attention_dropout: float = 0.,\n                 dropout: float = 0.1,\n                 drop_path: float = 0.,\n                 layernorm_epsilon: float = 1e-6,\n                 activation: Callable = nn.functional.gelu,\n                 representation_size: int = None,\n                 dtype: dtype = None,\n                 bias: bool = True,\n                 checkpoint: bool = False,\n                 init_method: str = 'torch',\n                 first_stage=True,\n                 last_stage=True,\n                 start_idx=None,\n                 end_idx=None,):\n        super().__init__()\n        layers = []\n        if first_stage:\n            embed = ViTEmbedding(img_size=img_size,\n                                 patch_size=patch_size,\n                                 in_chans=in_chans,\n                                 embedding_dim=dim,\n                                 dropout=dropout,\n                                 dtype=dtype,\n                                 init_method=init_method)\n            layers.append(embed)\n        # stochastic depth decay rule\n        dpr = [x.item() for x in torch.linspace(0, drop_path, depth)]\n        if start_idx is None and end_idx is None:\n            start_idx = 0\n            end_idx = depth\n        blocks = [\n            ViTBlock(\n                dim=dim,\n                num_heads=num_heads,\n                mlp_ratio=mlp_ratio,\n                attention_dropout=attention_dropout,\n                dropout=dropout,\n                drop_path=dpr[i],\n                activation=activation,\n                dtype=dtype,\n                bias=bias,\n                checkpoint=checkpoint,\n                init_method=init_method,\n            ) for i in range(start_idx, end_idx)\n        ]\n        layers.extend(blocks)\n        if last_stage:\n            norm = col_nn.LayerNorm(normalized_shape=dim, eps=layernorm_epsilon, dtype=dtype)\n            head = ViTHead(dim=dim,\n                           num_classes=num_classes,\n                           representation_size=representation_size,\n                           dtype=dtype,\n                           bias=bias,\n                           init_method=init_method)\n            layers.extend([norm, head])\n        self.layers = nn.Sequential(\n            *layers\n        )\n    def forward(self, x):\n        x = self.layers(x)\n        return x\ndef _filter_kwargs(func, kwargs):\n    sig = inspect.signature(func)\n    return {k: v for k, v in kwargs.items() if k in sig.parameters}\ndef _build_pipeline_vit(module_cls, num_layers, num_chunks, device=torch.device('cuda'), **kwargs):\n    logger = get_dist_logger()\n    if gpc.is_initialized(ParallelMode.PIPELINE):\n        pipeline_size = gpc.get_world_size(ParallelMode.PIPELINE)\n        pipeline_rank = gpc.get_local_rank(ParallelMode.PIPELINE)\n    else:\n        pipeline_size = 1\n        pipeline_rank = 0\n    rank = gpc.get_global_rank()\n    parts = partition_uniform(num_layers, pipeline_size, num_chunks)[pipeline_rank]\n    models = []\n    for start, end in parts:\n        kwargs['first_stage'] = start == 0\n        kwargs['last_stage'] = end == num_layers\n        kwargs['start_idx'] = start\n        kwargs['end_idx'] = end\n        logger.info(f'Rank{rank} build layer {start}-{end}, {end-start}/{num_layers} layers')\n        chunk = module_cls(**_filter_kwargs(module_cls.__init__, kwargs)).to(device)\n        models.append(chunk)\n    if len(models) == 1:\n        model = models[0]\n    else:\n        model = nn.ModuleList(models)\n    return model\ndef build_pipeline_vit(num_layers, num_chunks, device=torch.device('cuda'), **kwargs):\n    return _build_pipeline_vit(PipelineVisionTransformer, num_layers, num_chunks, device, **kwargs)\n")),(0,l.kt)("h3",{id:"\u4fee\u6539\u8bad\u7ec3\u811a\u672c-hybrid_paralleltrain_with_cifar10py"},"\u4fee\u6539\u8bad\u7ec3\u811a\u672c (",(0,l.kt)("inlineCode",{parentName:"h3"},"/hybrid_parallel/train_with_cifar10.py"),")"),(0,l.kt)("h4",{id:"\u5bfc\u5165\u6a21\u5757-1"},"\u5bfc\u5165\u6a21\u5757"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.engine.schedule import (InterleavedPipelineSchedule,\n                                        PipelineSchedule)\nfrom colossalai.utils import MultiTimer\nimport os\nimport colossalai\nimport torch\nfrom colossalai.context import ParallelMode\nfrom colossalai.core import global_context as gpc\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.nn import CrossEntropyLoss\nfrom colossalai.nn.lr_scheduler import CosineAnnealingWarmupLR\nfrom colossalai.utils import is_using_pp, get_dataloader\nfrom model.vit import build_pipeline_vit\nfrom model_zoo.vit.vit import _create_vit_model\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\n")),(0,l.kt)("h4",{id:"\u542f\u52a8-colossal-ai-1"},"\u542f\u52a8 Colossal-AI"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"colossalai.utils.is_using_pp")," \u53ef\u4ee5\u5e2e\u60a8\u68c0\u67e5\u914d\u7f6e\u6587\u4ef6\u662f\u5426\u6ee1\u8db3\u6d41\u6c34\u7ebf\u5e76\u884c\u7684\u8981\u6c42\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# initialize distributed setting\nparser = colossalai.get_default_parser()\nargs = parser.parse_args()\n# launch from torch\ncolossalai.launch_from_torch(config=args.config)\n# get logger\nlogger = get_dist_logger()\nlogger.info(\"initialized distributed environment\", ranks=[0])\nif hasattr(gpc.config, 'LOG_PATH'):\n    if gpc.get_global_rank() == 0:\n        log_path = gpc.config.LOG_PATH\n        if not os.path.exists(log_path):\n            os.mkdir(log_path)\n        logger.log_to_file(log_path)\nuse_pipeline = is_using_pp()\n")),(0,l.kt)("h4",{id:"\u5b9a\u4e49\u6a21\u578b"},"\u5b9a\u4e49\u6a21\u578b"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# create model\nmodel_kwargs = dict(img_size=gpc.config.IMG_SIZE,\n                    patch_size=gpc.config.PATCH_SIZE,\n                    dim=gpc.config.HIDDEN_SIZE,\n                    depth=gpc.config.DEPTH,\n                    num_heads=gpc.config.NUM_HEADS,\n                    mlp_ratio=gpc.config.MLP_RATIO,\n                    num_classes=gpc.config.NUM_CLASSES,\n                    init_method='jax',\n                    checkpoint=gpc.config.CHECKPOINT)\nif use_pipeline:\n    model = build_pipeline_vit(num_layers=model_kwargs['depth'], num_chunks=1, **model_kwargs)\nelse:\n    model = _create_vit_model(**model_kwargs)\n")),(0,l.kt)("h4",{id:"\u8ba1\u7b97\u53c2\u6570\u4e2a\u6570"},"\u8ba1\u7b97\u53c2\u6570\u4e2a\u6570"),(0,l.kt)("p",null,"\u60a8\u53ef\u4ee5\u8f7b\u677e\u8ba1\u7b97\u4e0d\u540c\u6d41\u6c34\u7ebf\u9636\u6bb5\u4e0a\u7684\u6a21\u578b\u53c2\u6570\u4e2a\u6570\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},'# count number of parameters\ntotal_numel = 0\nfor p in model.parameters():\n    total_numel += p.numel()\nif not gpc.is_initialized(ParallelMode.PIPELINE):\n    pipeline_stage = 0\nelse:\n    pipeline_stage = gpc.get_local_rank(ParallelMode.PIPELINE)\nlogger.info(f"number of parameters: {total_numel} on pipeline stage {pipeline_stage}")\n')),(0,l.kt)("h4",{id:"\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668\u4f18\u5316\u5668\u7b49\u7ec4\u4ef6"},"\u6784\u5efa\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u4f18\u5316\u5668\u7b49\u7ec4\u4ef6"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def build_cifar(batch_size):\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(224, pad_if_needed=True),\n        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    transform_test = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    train_dataset = CIFAR10(root=os.environ['DATA'], train=True, download=True, transform=transform_train)\n    test_dataset = CIFAR10(root=os.environ['DATA'], train=False, transform=transform_test)\n    train_dataloader = get_dataloader(dataset=train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n    test_dataloader = get_dataloader(dataset=test_dataset, batch_size=batch_size, pin_memory=True)\n    return train_dataloader, test_dataloader\n\n\n# craete dataloaders\ntrain_dataloader , test_dataloader = build_cifar()\n# create loss function\ncriterion = CrossEntropyLoss(label_smoothing=0.1)\n# create optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=gpc.config.LEARNING_RATE, weight_decay=gpc.config.WEIGHT_DECAY)\n# create lr scheduler\nlr_scheduler = CosineAnnealingWarmupLR(optimizer=optimizer,\n                                       total_steps=gpc.config.NUM_EPOCHS,\n                                       warmup_steps=gpc.config.WARMUP_EPOCHS)\n")),(0,l.kt)("h4",{id:"\u542f\u52a8-colossal-ai-\u5f15\u64ce"},"\u542f\u52a8 Colossal-AI \u5f15\u64ce"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'# intiailize\nengine, train_dataloader, test_dataloader, _ = colossalai.initialize(model=model,\n                                                                     optimizer=optimizer,\n                                                                     criterion=criterion,\n                                                                     train_dataloader=train_dataloader,\n                                                                     test_dataloader=test_dataloader)\nlogger.info("Engine is built", ranks=[0])\n')),(0,l.kt)("h4",{id:"\u8bad\u7ec3\u57fa\u4e8eengine"},"\u8bad\u7ec3\uff1a\u57fa\u4e8eengine"),(0,l.kt)("p",null,"\u5728\u6570\u636e\u5e76\u884c\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528 Trainer API \u8bad\u7ec3\u6a21\u578b\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u76f4\u63a5\u8bad\u7ec3\u57fa\u4e8e engine \u7684\u6a21\u578b\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u66f4\u591a\u529f\u80fd\u81ea\u5b9a\u4e49\u8bad\u7ec3\u65b9\u6cd5\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"data_iter = iter(train_dataloader)\nfor epoch in range(gpc.config.NUM_EPOCHS):\n    # training\n    engine.train()\n    if gpc.get_global_rank() == 0:\n        description = 'Epoch {} / {}'.format(\n            epoch,\n            gpc.config.NUM_EPOCHS\n        )\n        progress = tqdm(range(len(train_dataloader)), desc=description)\n    else:\n        progress = range(len(train_dataloader))\n    for _ in progress:\n        engine.zero_grad()\n        engine.execute_schedule(data_iter, return_output_label=False)\n        engine.step()\n        lr_scheduler.step()\n")),(0,l.kt)("h3",{id:"\u5f00\u59cb\u8bad\u7ec3-1"},"\u5f00\u59cb\u8bad\u7ec3"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"export DATA=<path_to_dataset>\n# If your torch >= 1.10.0\ntorchrun --standalone --nproc_per_node <NUM_GPUs>  train_hybrid.py --config ./configs/config_pipeline_parallel.py\n# If your torch >= 1.9.0\n# python -m torch.distributed.run --standalone --nproc_per_node= <NUM_GPUs> train_hybrid.py --config ./configs/config_pipeline_parallel.py\n")),(0,l.kt)("h2",{id:"\u5f20\u91cf\u5e76\u884c\u548c\u5f02\u6784\u5e76\u884c"},"\u5f20\u91cf\u5e76\u884c\u548c\u5f02\u6784\u5e76\u884c"),(0,l.kt)("p",null,"\u5f20\u91cf\u5e76\u884c\u5c06\u6bcf\u4e2a\u6743\u91cd\u53c2\u6570\u8de8\u591a\u4e2a\u8bbe\u5907\u8fdb\u884c\u5206\u533a\uff0c\u4ee5\u51cf\u5c11\u5185\u5b58\u8d1f\u8f7d\u3002Colossal-AI \u652f\u6301 1D\u30012D\u30012.5D \u548c 3D \u5f20\u91cf\u5e76\u884c\u3002\u6b64\u5916\uff0c\u8fd8\u53ef\u4ee5\u5c06\u5f20\u91cf\u5e76\u884c\u3001\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u6570\u636e\u5e76\u884c\u7ed3\u5408\u8d77\u6765\uff0c\u5b9e\u73b0\u6df7\u5408\u5e76\u884c\u3002Colossal-AI \u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u5e94\u7528\u5f20\u91cf\u5e76\u884c\u548c\u6df7\u5408\u5e76\u884c\u3002\u53ea\u9700\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u66f4\u6539\u51e0\u884c\u4ee3\u7801\u5373\u53ef\u5b9e\u73b0\u6d41\u6c34\u7ebf\u5e76\u884c\u3002"),(0,l.kt)("h3",{id:"\u6784\u9020\u60a8\u7684\u914d\u7f6e\u6587\u4ef6-hybrid_parallelconfigsvit_1d_tp2_pp2py"},"\u6784\u9020\u60a8\u7684\u914d\u7f6e\u6587\u4ef6 (",(0,l.kt)("inlineCode",{parentName:"h3"},"/hybrid_parallel/configs/vit_1d_tp2_pp2.py"),")"),(0,l.kt)("p",null,"\u4f7f\u7528\u5f20\u91cf\u5e76\u884c\uff0c\u53ea\u9700\u5c06\u76f8\u5173\u4fe1\u606f\u6dfb\u52a0\u5230 ",(0,l.kt)("strong",{parentName:"p"},"parallel dict"),"\u3002\u5177\u4f53\u800c\u8a00\uff0c",(0,l.kt)("inlineCode",{parentName:"p"},"TENSOR_PARALLEL_MODE")," \u53ef\u4ee5\u662f\u201c1d\u201d\u3001\u201c2d\u201d\u3001\u201c2.5d\u201d\u3001\u201c3d\u201d\u3002\u4e0d\u540c\u5e76\u884c\u5ea6\u7684\u5927\u5c0f\u5e94\u6ee1\u8db3\uff1a",(0,l.kt)("inlineCode",{parentName:"p"},"#GPUs = pipeline parallel size x tensor parallel size x data parallel size"),"\u3002\u5728\u6307\u5b9a GPU \u6570\u91cf\u3001\u6d41\u6c34\u7ebf\u5e76\u884c\u5927\u5c0f\u548c\u5f20\u91cf\u5e76\u884c\u5927\u5c0f\u540e ",(0,l.kt)("inlineCode",{parentName:"p"},"data parallel size")," \u4f1a\u81ea\u52a8\u8ba1\u7b97\u3002"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.amp import AMP_TYPE\n# parallel setting\nTENSOR_PARALLEL_SIZE = 2\nTENSOR_PARALLEL_MODE = '1d'\nparallel = dict(\n    pipeline=2,\n    tensor=dict(mode=TENSOR_PARALLEL_MODE, size=TENSOR_PARALLEL_SIZE)\n)\nfp16 = dict(mode=AMP_TYPE.NAIVE)\nclip_grad_norm = 1.0\n# pipeline config\nNUM_MICRO_BATCHES = parallel['pipeline']\nTENSOR_SHAPE = (BATCH_SIZE // NUM_MICRO_BATCHES, SEQ_LENGTH, HIDDEN_SIZE)\n")),(0,l.kt)("p",null,"\u5176\u4ed6\u914d\u7f6e:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# hyperparameters\n# BATCH_SIZE is as per GPU\n# global batch size = BATCH_SIZE x data parallel size\nBATCH_SIZE = 256\nLEARNING_RATE = 3e-3\nWEIGHT_DECAY = 0.3\nNUM_EPOCHS = 300\nWARMUP_EPOCHS = 32\n# model config\nIMG_SIZE = 224\nPATCH_SIZE = 16\nHIDDEN_SIZE = 768\nDEPTH = 12\nNUM_HEADS = 12\nMLP_RATIO = 4\nNUM_CLASSES = 10\nCHECKPOINT = True\nSEQ_LENGTH = (IMG_SIZE // PATCH_SIZE) ** 2 + 1  # add 1 for cls token\n")),(0,l.kt)("h3",{id:"\u5f00\u59cb\u8bad\u7ec3-2"},"\u5f00\u59cb\u8bad\u7ec3"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"export DATA=<path_to_dataset>\n# If your torch >= 1.10.0\ntorchrun --standalone --nproc_per_node <NUM_GPUs>  train_hybrid.py --config ./configs/config_hybrid_parallel.py\n# If your torch >= 1.9.0\n# python -m torch.distributed.run --standalone --nproc_per_node= <NUM_GPUs> train_hybrid.py --config ./configs/config_hybrid_parallel.py\n")))}_.isMDXComponent=!0}}]);