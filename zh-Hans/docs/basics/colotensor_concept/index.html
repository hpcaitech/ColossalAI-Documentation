<!doctype html>
<html class="docs-version-v0.2.2" lang="zh-Hans" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/zh-Hans/blog/rss.xml" title="Colossal-AI RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-Hans/blog/atom.xml" title="Colossal-AI Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1XKZVCCKRZ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1XKZVCCKRZ",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Colossal-AI" href="/zh-Hans/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="https://snack.expo.io/embed.js" async></script>
<script src="https://js-eu1.hs-scripts.com/26563514.js" async defer="defer" id="hs-script-loader"></script><title data-react-helmet="true">ColoTensor Concepts | Colossal-AI</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://colossalai.org/zh-Hans/docs/basics/colotensor_concept"><meta data-react-helmet="true" name="docsearch:language" content="zh-Hans"><meta data-react-helmet="true" name="docsearch:version" content="v0.2.2"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-v0.2.2"><meta data-react-helmet="true" property="og:title" content="ColoTensor Concepts | Colossal-AI"><meta data-react-helmet="true" name="description" content="Author: Jiarui Fang, Hongxin Liu and Haichen Huang"><meta data-react-helmet="true" property="og:description" content="Author: Jiarui Fang, Hongxin Liu and Haichen Huang"><link data-react-helmet="true" rel="icon" href="/zh-Hans/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://colossalai.org/zh-Hans/docs/basics/colotensor_concept"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/basics/colotensor_concept" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/zh-Hans/docs/basics/colotensor_concept" hreflang="zh-Hans"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/basics/colotensor_concept" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://XP2V2KAOVI-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/zh-Hans/assets/css/styles.b5c97f7b.css">
<link rel="preload" href="/zh-Hans/assets/js/runtime~main.aab5813c.js" as="script">
<link rel="preload" href="/zh-Hans/assets/js/main.255c5581.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet"><div class="Toastify"></div><div><a href="#" class="skipToContent_1oUP">跳到主要内容</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner InnerContainer_1wkI"><div class="navbar__items"><a class="navbar__brand" href="/zh-Hans/"><div class="navbar__logo"><img src="/zh-Hans/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--light_3UqQ"><img src="/zh-Hans/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--dark_hz6m"></div><b class="navbar__title"> </b></a><a class="navbar__item navbar__link" href="/zh-Hans/docs/get_started/installation">教程</a><a href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">例子</a><a href="http://docs.colossalai.org" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API文档</a><a href="https://www.hpc-ai.tech/blog" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">博客</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/zh-Hans/docs/advanced_tutorials/add_your_parallel">v0.2.2</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_3vod"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>简体中文</span></span></a><ul class="dropdown__menu"><li><a href="/docs/basics/colotensor_concept" target="_self" rel="noopener noreferrer" class="dropdown__link">English</a></li><li><a href="/zh-Hans/docs/basics/colotensor_concept" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active">简体中文</a></li></ul></div><div class="displayOnlyInLargeViewport_2uzv IconContainer_aWwG"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="Icon_3e04" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div><div class="toggle_71bT toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">🌜</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">🌞</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1ZXk"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="Wrapper_ReNv main-docs-wrapper"><div class="docPage_3AUJ"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_35hR" type="button"></button><main class="docMainContainer_2AUC"><div class="padding-vert--lg container docItemWrapper_1WZa"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>ColoTensor Concepts</h1></header><p>Author: <a href="https://github.com/feifeibear" target="_blank" rel="noopener noreferrer">Jiarui Fang</a>, <a href="https://github.com/ver217" target="_blank" rel="noopener noreferrer">Hongxin Liu</a> and <a href="https://github.com/1SAA" target="_blank" rel="noopener noreferrer">Haichen Huang</a></p><p><strong>Prerequisite:</strong></p><ul><li><a href="/zh-Hans/docs/concepts/colossalai_overview">Colossal-AI Overview</a></li><li><a href="/zh-Hans/docs/concepts/distributed_training">Distributed Training</a></li><li><a href="/zh-Hans/docs/concepts/paradigms_of_parallelism">Paradigms of Parallelism</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="introduction">Introduction<a class="hash-link" href="#introduction" title="标题的直接链接">​</a></h2><p>在ColossalAI 0.1.8 版本之后，<a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.html#colossalai.tensor.ColoTensor" target="_blank" rel="noopener noreferrer">ColoTensor</a> 成为 ColossalAI 中张量的基本数据结构。 它是 torch.Tensor 的子类，可以当做 PyTorch Tensor使用。 此外，一些独特的功能使其能够表示一个payload分布在多个 GPU 设备上的Global  Tensor，并提供一些列方式操作这个Global Tensor。 在 ColoTensor 的帮助下，用户可以以类似编写串行程序方式，编写的分布式 DNN 训练程序。</p><p>ColoTensor 包含额外的属性<a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.tensor_spec.html#colossalai.tensor.tensor_spec.ColoTensorSpec" target="_blank" rel="noopener noreferrer">ColoTensorSpec</a>
来描述张量的payload分布和计算模式。</p><ul><li>ProcessGroup：如何将进程组织为通信组。</li><li>Distributed Spec：张量如何在进程组之间分布。</li><li>Compute Spec：计算过程中如何使用张量。</li></ul><p>我们一一详述。</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="processgroup">ProcessGroup<a class="hash-link" href="#processgroup" title="标题的直接链接">​</a></h2><p><a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.html#colossalai.tensor.ProcessGroup" target="_blank" rel="noopener noreferrer">ProcessGroup</a> 类的一个实例描述了如何在进程组中组织进程。进程组内的进程可以一起参与同一个集合通信，比如allgather, allreduce等。进程组组织方式被张量的并行策略支配。比如，如果用户定义了Tensor的张量并行（TP），数据并行（DP）方式，那么进程组的进程组织方式将被自动推导出来。 进程组设置可能因不同的张量而异。 因此，它使我们能够支持更复杂的混合并行。流水线并行(PP)定义不在ProcessGroup中描述，它需要另一套机制，我们将在未来补充ColoTensor应用于PP的相关内容。</p><p>目前，ColoTensor 的一个进程组由 tp_degree 和 dp_degree 两种配置定义。 在 DP+TP 混合并行的情况下，可以将设备视为 2D 网格。 我们将 TP 通信组放置在设备网格的前导低维上，然后将数据并行组放置在设备网格的高维上。 原因是张量并行比数据并行具有更大的通信开销。 相邻设备放置在一个 TP 进程组内，并且通常放置在同一个节点中。</p><p>考虑到8个进程配置为tp_degree=4，dp_degree=2，布局如下图。 进程组 tp0 包含 gpu 0,1,2,3。 进程 dp1 包含 gpu 1 和 5。</p><figure style="text-align:center"><img src="https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ColoTensor_layout_demo.PNG"><figcaption>Process Group using tp_degree=4, dp_degree=2</figcaption></figure><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="distributed-spec">Distributed Spec<a class="hash-link" href="#distributed-spec" title="标题的直接链接">​</a></h2><p><a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.distspec.html" target="_blank" rel="noopener noreferrer">Distributed Spec</a>描述了 ColoTensor 如何在 ProcessGroup 中分布。</p><p>张量在 DP 进程组之间的分布方式是自动导出的，不需要用户手动指定。 如果这个张量是一个模型参数，它会在 DP 进程组中被复制。 如果是activation张量，则沿tensor最高维度在DP进程组中进行平均分割。</p><p>因此，在使用 Distributed Spec 时，我们只需要描述张量在 TP 进程组之间的分布方式即可。 TP 进程组目前有两种分布式规范，即 <a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.distspec.html#colossalai.tensor.distspec.ShardSpec" target="_blank" rel="noopener noreferrer">ShardSpec</a>和<a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.distspec.html#colossalai.tensor.distspec.ReplicaSpec" target="_blank" rel="noopener noreferrer">ReplicaSpec</a>。 ShardSpec 需要指定分区的维度索引 dim 和分区个数 num_partitions。 目前，我们仅支持在单个dim上进行拆分。 TP进程组上不同的dist spec可以通过set_dist_spec()接口相互转换。这些转化操作可以被记录在PyTorch的自动求导机制中，并在反向传播时候触发对应的反向操作。</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="compute-spec">Compute Spec<a class="hash-link" href="#compute-spec" title="标题的直接链接">​</a></h2><p><a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.compute_spec.html#colossalai.tensor.compute_spec.ComputeSpec" target="_blank" rel="noopener noreferrer">ComputeSpec</a>类描述Tensor如何参与计算。目前，我们将作为module parameter的ColoTensor设置正确的Compute Pattern。可以触发正取的计算模式。具体应用方式我们会在接下来的文档中展示。</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="coloparameter">ColoParameter<a class="hash-link" href="#coloparameter" title="标题的直接链接">​</a></h2><p><a href="https://colossalai.readthedocs.io/en/latest/colossalai/colossalai.tensor.colo_parameter.html#colossalai.tensor.colo_parameter.ColoParameter" target="_blank" rel="noopener noreferrer">ColoParameter</a>是ColoTensor的子类。用来声明Parameter。他和ColoTensor关系和Torch.Tensor和torch.Parameter一致。后者可以让tensor出现在module的parameters()和name_parameters() 的返回值中。</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="example">Example<a class="hash-link" href="#example" title="标题的直接链接">​</a></h2><p>让我们看一个例子。 使用 tp_degree=4, dp_dgree=2 在 8 个 GPU 上初始化并Shard一个ColoTensor。 然后tensor被沿着 TP 进程组中的最后一个维度进行分片。 最后，我们沿着 TP 进程组中的第一个维度（dim 0）对其进行重新Shard。 我们鼓励用户运行代码并观察每个张量的形状。</p><div class="codeBlockContainer_K1bP language-python theme-code-block"><div class="codeBlockContent_hGly python"><pre tabindex="0" class="prism-code language-python codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">multiprocessing </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> mp</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> colossalai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">utils </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> free_port</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> print_rank_0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> functools </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> partial</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> colossalai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> colossalai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tensor </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ProcessGroup</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ColoTensor</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ColoTensorSpec</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ShardSpec</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ComputeSpec</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ComputePattern</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> colossalai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">utils </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> free_port</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">run_dist_tests</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">rank</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> world_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> port</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    colossalai</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">launch</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">config</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> rank</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">rank</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> world_size</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">world_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> host</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;localhost&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> port</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">port</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> backend</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;nccl&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pg </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ProcessGroup</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tp_degree</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dp_degree</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">manual_seed</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    local_tensor </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print_rank_0</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;shape </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">local_tensor</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">shape</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">, </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">local_tensor</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">data</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spec </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ColoTensorSpec</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pg</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ShardSpec</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dims</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_partitions</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">pg</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tp_world_size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ComputeSpec</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ComputePattern</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">TP1D</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    t1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ColoTensor</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_torch_tensor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">local_tensor</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> spec</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    t1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> t1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to_replicate</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print_rank_0</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;shape </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">t1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">shape</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">, </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">t1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">data</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spec2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ShardSpec</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">pg</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tp_world_size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    t1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">set_dist_spec</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">spec2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print_rank_0</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;shape </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">t1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">shape</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">, </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">t1</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">data</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">test_dist_cases</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">world_size</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    run_func </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> partial</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">run_dist_tests</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> world_size</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">world_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> port</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">free_port</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mp</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">spawn</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">run_func</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nprocs</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">world_size</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> __name__ </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;__main__&#x27;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    test_dist_cases</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="复制代码到剪贴板" class="copyButton_Ue-o clean-btn">复制</button></div></div><div class="admonition admonition-caution alert alert--warning"><div class="admonition-heading"><h5><span class="admonition-icon">⚠️</span>caution</h5></div><div class="admonition-content"><p>The ColoTensor is an experimental feature and may be updated.</p></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#processgroup" class="table-of-contents__link toc-highlight">ProcessGroup</a></li><li><a href="#distributed-spec" class="table-of-contents__link toc-highlight">Distributed Spec</a></li><li><a href="#compute-spec" class="table-of-contents__link toc-highlight">Compute Spec</a></li><li><a href="#coloparameter" class="table-of-contents__link toc-highlight">ColoParameter</a></li><li><a href="#example" class="table-of-contents__link toc-highlight">Example</a></li></ul></div></div></div></div></main></div></div><footer class="footer Container_ZO7N"><div class="InnerContainer_kEOB"><div class="ContentContainer_Bd2W"><div class="FooterLeft_UU7Q"><div class="BrandContainer_37NB"><img class="BrandImage_1lbV" alt="AgileTs Logo" height="30" src="/img/logo.svg"></div><div class="Tagline_2AGk">具有高效并行化技术的集成大规模模型训练系统</div><button class="ButtonContainer_oPl2 GithubButton_1Y3L"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="GithubIcon_3htU" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><div>GITHUB</div></button></div><div class="FooterRight_1NHD"><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">资源</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="/zh-Hans/docs/get_started/installation" label="教程" to="docs/get_started/installation">教程</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="http://docs.colossalai.org" label="API文档" to="http://docs.colossalai.org">API文档</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" label="例子" to="https://github.com/hpcaitech/ColossalAI/tree/main/examples">例子</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/discussions" label="论坛" to="https://github.com/hpcaitech/ColossalAI/discussions">论坛</a></ul></div><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">社区</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI" rel="noopener noreferrer" target="_blank" label="GitHub">GitHub</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://www.hpc-ai.tech/blog" rel="noopener noreferrer" target="_blank" label="博客">博客</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://twitter.com/HPCAITech" rel="noopener noreferrer" target="_blank" label="Twitter">Twitter</a></ul></div></div></div><div class="BottomContainer_1let"><div class="CopyrightText_25Fq">Copyright © 2023 All Rights Reserved by Luchen Technology Inc.</div></div></div></footer></div>
<script src="/zh-Hans/assets/js/runtime~main.aab5813c.js"></script>
<script src="/zh-Hans/assets/js/main.255c5581.js"></script>
</body>
</html>