<!doctype html>
<html class="docs-version-v0.2.2" lang="zh-Hans" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/zh-Hans/blog/rss.xml" title="Colossal-AI RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-Hans/blog/atom.xml" title="Colossal-AI Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1XKZVCCKRZ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1XKZVCCKRZ",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="Colossal-AI" href="/zh-Hans/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="https://snack.expo.io/embed.js" async></script>
<script src="https://js-eu1.hs-scripts.com/26563514.js" async defer="defer" id="hs-script-loader"></script><title data-react-helmet="true">并行技术 | Colossal-AI</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://colossalai.org/zh-Hans/docs/concepts/paradigms_of_parallelism"><meta data-react-helmet="true" name="docsearch:language" content="zh-Hans"><meta data-react-helmet="true" name="docsearch:version" content="v0.2.2"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-v0.2.2"><meta data-react-helmet="true" property="og:title" content="并行技术 | Colossal-AI"><meta data-react-helmet="true" name="description" content="作者: Shenggui Li, Siqi Mai"><meta data-react-helmet="true" property="og:description" content="作者: Shenggui Li, Siqi Mai"><link data-react-helmet="true" rel="icon" href="/zh-Hans/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://colossalai.org/zh-Hans/docs/concepts/paradigms_of_parallelism"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/concepts/paradigms_of_parallelism" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/zh-Hans/docs/concepts/paradigms_of_parallelism" hreflang="zh-Hans"><link data-react-helmet="true" rel="alternate" href="https://colossalai.org/docs/concepts/paradigms_of_parallelism" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://XP2V2KAOVI-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/zh-Hans/assets/css/styles.b5c97f7b.css">
<link rel="preload" href="/zh-Hans/assets/js/runtime~main.aab5813c.js" as="script">
<link rel="preload" href="/zh-Hans/assets/js/main.255c5581.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet"><div class="Toastify"></div><div><a href="#" class="skipToContent_1oUP">跳到主要内容</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner InnerContainer_1wkI"><div class="navbar__items"><a class="navbar__brand" href="/zh-Hans/"><div class="navbar__logo"><img src="/zh-Hans/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--light_3UqQ"><img src="/zh-Hans/img/logo.svg" alt="Colossal-AI" class="themedImage_1VuW themedImage--dark_hz6m"></div><b class="navbar__title"> </b></a><a class="navbar__item navbar__link" href="/zh-Hans/docs/get_started/installation">教程</a><a href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">例子</a><a href="http://docs.colossalai.org" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API文档</a><a href="https://www.hpc-ai.tech/blog" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">博客</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/zh-Hans/docs/advanced_tutorials/add_your_parallel">v0.2.2</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_3vod"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>简体中文</span></span></a><ul class="dropdown__menu"><li><a href="/docs/concepts/paradigms_of_parallelism" target="_self" rel="noopener noreferrer" class="dropdown__link">English</a></li><li><a href="/zh-Hans/docs/concepts/paradigms_of_parallelism" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active">简体中文</a></li></ul></div><div class="displayOnlyInLargeViewport_2uzv IconContainer_aWwG"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="Icon_3e04" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div><div class="toggle_71bT toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">🌜</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">🌞</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1ZXk"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="Wrapper_ReNv main-docs-wrapper"><div class="docPage_3AUJ"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_35hR" type="button"></button><main class="docMainContainer_2AUC"><div class="padding-vert--lg container docItemWrapper_1WZa"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>并行技术</h1></header><p>作者: Shenggui Li, Siqi Mai</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="简介">简介<a class="hash-link" href="#简介" title="标题的直接链接">​</a></h2><p>随着深度学习的发展，对并行训练的需求越来越大。这是因为模型和数据集越来越大，如果我们坚持使用单 GPU 训练，训练过程的等待将会成为一场噩梦。在本节中，我们将对现有的并行训练方法进行简要介绍。如果您想对这篇文章进行补充，欢迎在<a href="https://github.com/hpcaitech/ColossalAI/discussions" target="_blank" rel="noopener noreferrer">GitHub论坛</a>上进行讨论。</p><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="数据并行">数据并行<a class="hash-link" href="#数据并行" title="标题的直接链接">​</a></h2><p>数据并行是最常见的并行形式，因为它很简单。在数据并行训练中，数据集被分割成几个碎片，每个碎片被分配到一个设备上。这相当于沿批次维度对训练过程进行并行化。每个设备将持有一个完整的模型副本，并在分配的数据集碎片上进行训练。在反向传播之后，模型的梯度将被全部减少，以便在不同设备上的模型参数能够保持同步。</p><figure style="text-align:center"><img src="https://s2.loli.net/2022/01/28/WSAensMqjwHdOlR.png"><figcaption>数据并行</figcaption></figure><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="模型并行">模型并行<a class="hash-link" href="#模型并行" title="标题的直接链接">​</a></h2><p>在数据并行训练中，一个明显的特点是每个 GPU 持有整个模型权重的副本。这就带来了冗余问题。另一种并行模式是模型并行，即模型被分割并分布在一个设备阵列上。通常有两种类型的并行：张量并行和流水线并行。张量并行是在一个操作中进行并行计算，如矩阵-矩阵乘法。流水线并行是在各层之间进行并行计算。因此，从另一个角度来看，张量并行可以被看作是层内并行，流水线并行可以被看作是层间并行。</p><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="张量并行">张量并行<a class="hash-link" href="#张量并行" title="标题的直接链接">​</a></h3><p>张量并行训练是将一个张量沿特定维度分成 <code>N</code> 块，每个设备只持有整个张量的 <code>1/N</code>，同时不影响计算图的正确性。这需要额外的通信来确保结果的正确性。</p><p>以一般的矩阵乘法为例，假设我们有 <code>C = AB</code>。我们可以将B沿着列分割成 <code>[B0 B1 B2 ... Bn]</code>，每个设备持有一列。然后我们将 <code>A</code> 与每个设备上 <code>B</code> 中的每一列相乘，我们将得到 <code>[AB0 AB1 AB2 ... ABn]</code> 。此刻，每个设备仍然持有一部分的结果，例如，设备(rank=0)持有 <code>AB0</code>。为了确保结果的正确性，我们需要收集全部的结果，并沿列维串联张量。通过这种方式，我们能够将张量分布在设备上，同时确保计算流程保持正确。</p><figure style="text-align:center"><img src="https://s2.loli.net/2022/01/28/2ZwyPDvXANW4tMG.png"><figcaption>张量并行</figcaption></figure><p>在 Colossal-AI 中，我们提供了一系列的张量并行方法，即 1D、2D、2.5D 和 3D 张量并行。我们将在<code>高级教程</code>中详细讨论它们。</p><p>相关文章:</p><ul><li><a href="https://arxiv.org/abs/2006.16668" target="_blank" rel="noopener noreferrer">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li><li><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener noreferrer">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></li><li><a href="https://arxiv.org/abs/2104.05343" target="_blank" rel="noopener noreferrer">An Efficient 2D Method for Training Super-Large Deep Learning Models</a></li><li><a href="https://arxiv.org/abs/2105.14500" target="_blank" rel="noopener noreferrer">2.5-dimensional distributed model training</a></li><li><a href="https://arxiv.org/abs/2105.14450" target="_blank" rel="noopener noreferrer">Maximizing Parallelism in Distributed Training for Huge Neural Networks</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="流水线并行">流水线并行<a class="hash-link" href="#流水线并行" title="标题的直接链接">​</a></h3><p>流水线并行一般来说很容易理解。请您回忆一下您的计算机结构课程，这确实存在于 CPU 设计中。</p><figure style="text-align:center"><img src="https://s2.loli.net/2022/01/28/at3eDv7kKBusxbd.png"><figcaption>流水线并行</figcaption></figure><p>流水线并行的核心思想是，模型按层分割成若干块，每块都交给一个设备。在前向传递过程中，每个设备将中间的激活传递给下一个阶段。在后向传递过程中，每个设备将输入张量的梯度传回给前一个流水线阶段。这允许设备同时进行计算，并增加了训练的吞吐量。流水线并行训练的一个缺点是，会有一些设备参与计算的冒泡时间，导致计算资源的浪费。</p><figure style="text-align:center"><img src="https://s2.loli.net/2022/01/28/sDNq51PS3Gxbw7F.png"><figcaption>Source: <a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener noreferrer">GPipe</a></figcaption></figure><p>相关文章:</p><ul><li><a href="https://arxiv.org/abs/1806.03377" target="_blank" rel="noopener noreferrer">PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a></li><li><a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener noreferrer">GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a></li><li><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener noreferrer">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></li><li><a href="https://arxiv.org/abs/2107.06925" target="_blank" rel="noopener noreferrer">Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="优化器相关的并行">优化器相关的并行<a class="hash-link" href="#优化器相关的并行" title="标题的直接链接">​</a></h2><p>另一种并行方法和优化器相关，目前这种并行最流行的方法是 <code>ZeRO</code>，即<a href="https://arxiv.org/abs/1910.02054" target="_blank" rel="noopener noreferrer">零冗余优化器</a>。 ZeRO 在三个层面上工作，以消除内存冗余（ZeRO需要进行fp16训练）。</p><ul><li>Level 1: 优化器状态在各进程中被划分。</li><li>Level 2: 用于更新模型权重的32位梯度也被划分，因此每个进程只存储与其优化器状态划分相对应的梯度。</li><li>Level 3: 16位模型参数在各进程中被划分。</li></ul><p>相关文章:</p><ul><li><a href="https://arxiv.org/abs/1910.02054" target="_blank" rel="noopener noreferrer">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_3R7-" id="异构系统的并行">异构系统的并行<a class="hash-link" href="#异构系统的并行" title="标题的直接链接">​</a></h2><p>上述方法通常需要大量的 GPU 来训练一个大型模型。然而，人们常常忽略的是，与 GPU 相比，CPU 的内存要大得多。在一个典型的服务器上，CPU 可以轻松拥有几百GB的内存，而每个 GPU 通常只有16或32GB的内存。这促使人们思考为什么 CPU 内存没有被用于分布式训练。</p><p>最近的进展是依靠 CPU 甚至是 NVMe 磁盘来训练大型模型。主要的想法是，在不使用张量时，将其卸载回 CPU 内存或 NVMe 磁盘。通过使用异构系统架构，有可能在一台机器上容纳一个巨大的模型。</p><figure style="text-align:center"><img src="https://s2.loli.net/2022/01/28/qLHD5lk97hXQdbv.png"><figcaption>异构系统</figcaption></figure><p>相关文章:</p><ul><li><a href="https://arxiv.org/abs/2104.07857" target="_blank" rel="noopener noreferrer">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li><li><a href="https://arxiv.org/abs/2108.05818" target="_blank" rel="noopener noreferrer">PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management</a></li></ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文档分页导航"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#简介" class="table-of-contents__link toc-highlight">简介</a></li><li><a href="#数据并行" class="table-of-contents__link toc-highlight">数据并行</a></li><li><a href="#模型并行" class="table-of-contents__link toc-highlight">模型并行</a><ul><li><a href="#张量并行" class="table-of-contents__link toc-highlight">张量并行</a></li><li><a href="#流水线并行" class="table-of-contents__link toc-highlight">流水线并行</a></li></ul></li><li><a href="#优化器相关的并行" class="table-of-contents__link toc-highlight">优化器相关的并行</a></li><li><a href="#异构系统的并行" class="table-of-contents__link toc-highlight">异构系统的并行</a></li></ul></div></div></div></div></main></div></div><footer class="footer Container_ZO7N"><div class="InnerContainer_kEOB"><div class="ContentContainer_Bd2W"><div class="FooterLeft_UU7Q"><div class="BrandContainer_37NB"><img class="BrandImage_1lbV" alt="AgileTs Logo" height="30" src="/img/logo.svg"></div><div class="Tagline_2AGk">具有高效并行化技术的集成大规模模型训练系统</div><button class="ButtonContainer_oPl2 GithubButton_1Y3L"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="GithubIcon_3htU" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><div>GITHUB</div></button></div><div class="FooterRight_1NHD"><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">资源</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="/zh-Hans/docs/get_started/installation" label="教程" to="docs/get_started/installation">教程</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="http://docs.colossalai.org" label="API文档" to="http://docs.colossalai.org">API文档</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/tree/main/examples" label="例子" to="https://github.com/hpcaitech/ColossalAI/tree/main/examples">例子</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI/discussions" label="论坛" to="https://github.com/hpcaitech/ColossalAI/discussions">论坛</a></ul></div><div class="SectionContainer_2QT6"><li class="LinkItemTitle_1y09">社区</li><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://github.com/hpcaitech/ColossalAI" rel="noopener noreferrer" target="_blank" label="GitHub">GitHub</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://www.hpc-ai.tech/blog" rel="noopener noreferrer" target="_blank" label="博客">博客</a></ul><ul class="LinkItemContainer_2Lmc"><a class="LinkText_1B0E" href="https://twitter.com/HPCAITech" rel="noopener noreferrer" target="_blank" label="Twitter">Twitter</a></ul></div></div></div><div class="BottomContainer_1let"><div class="CopyrightText_25Fq">Copyright © 2023 All Rights Reserved by Luchen Technology Inc.</div></div></div></footer></div>
<script src="/zh-Hans/assets/js/runtime~main.aab5813c.js"></script>
<script src="/zh-Hans/assets/js/main.255c5581.js"></script>
</body>
</html>