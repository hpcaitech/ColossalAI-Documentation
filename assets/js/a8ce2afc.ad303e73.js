"use strict";(self.webpackChunkagile_docs=self.webpackChunkagile_docs||[]).push([[4952],{3905:function(e,n,t){t.d(n,{Zo:function(){return d},kt:function(){return f}});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},l=Object.keys(e);for(r=0;r<l.length;r++)t=l[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)t=l[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var u=r.createContext({}),s=function(e){var n=r.useContext(u),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},d=function(e){var n=s(e.components);return r.createElement(u.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,l=e.originalType,u=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=s(t),f=o,m=p["".concat(u,".").concat(f)]||p[f]||c[f]||l;return t?r.createElement(m,a(a({ref:n},d),{},{components:t})):r.createElement(m,a({ref:n},d))}));function f(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var l=t.length,a=new Array(l);a[0]=p;var i={};for(var u in n)hasOwnProperty.call(n,u)&&(i[u]=n[u]);i.originalType=e,i.mdxType="string"==typeof e?e:o,a[1]=i;for(var s=2;s<l;s++)a[s]=t[s];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}p.displayName="MDXCreateElement"},5520:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return i},contentTitle:function(){return u},metadata:function(){return s},toc:function(){return d},default:function(){return p}});var r=t(3117),o=t(102),l=(t(7294),t(3905)),a=["components"],i={},u="Define your own parallel model",s={unversionedId:"advanced_tutorials/define_your_own_parallel_model",id:"version-v0.2.2/advanced_tutorials/define_your_own_parallel_model",title:"Define your own parallel model",description:"Author: Zhengda Bian, Yongbin Li",source:"@site/i18n/en/docusaurus-plugin-content-docs/version-v0.2.2/advanced_tutorials/define_your_own_parallel_model.md",sourceDirName:"advanced_tutorials",slug:"/advanced_tutorials/define_your_own_parallel_model",permalink:"/docs/advanced_tutorials/define_your_own_parallel_model",tags:[],version:"v0.2.2",frontMatter:{}},d=[{value:"Write a simple 2D parallel model",id:"write-a-simple-2d-parallel-model",children:[],level:2},{value:"Use pre-defined model",id:"use-pre-defined-model",children:[],level:2}],c={toc:d};function p(e){var n=e.components,t=(0,o.Z)(e,a);return(0,l.kt)("wrapper",(0,r.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"define-your-own-parallel-model"},"Define your own parallel model"),(0,l.kt)("p",null,"Author: Zhengda Bian, Yongbin Li"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"\u26a0\ufe0f We are working on this documentation to make it more detailed. We will introduce the mechanism of different parallelism\nand how to use them to write a model.")),(0,l.kt)("p",null,"Let's say that you have a huge MLP model with billions of parameters and its extremely large hidden layer size makes it\nimpossible to fit into a single GPU directly. Don't worry, Colossal-AI is here to help you sort things out. With the help of Colossal-AI,\nyou can write your model in the familiar way in which you used to write models for a single GPU, while Colossal-AI automatically\nsplits your model weights and fit them perfectly into a set of GPUs. We give a simple example showing how to write a simple\n2D parallel model in the Colossal-AI context."),(0,l.kt)("h2",{id:"write-a-simple-2d-parallel-model"},"Write a simple 2D parallel model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.nn import Linear2D\nimport torch.nn as nn\n\nclass MLP_2D(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.linear_1 = Linear2D(in_features=1024, out_features=16384)\n        self.linear_2 = Linear2D(in_features=16384, out_features=1024)\n\n    def forward(self, x):\n        x = self.linear_1(x)\n        x = self.linear_2(x)\n        return x\n")),(0,l.kt)("h2",{id:"use-pre-defined-model"},"Use pre-defined model"),(0,l.kt)("p",null,"For the sake of your convenience, we kindly provide you in our Model Zoo with some prevalent models such as ",(0,l.kt)("em",{parentName:"p"},"BERT"),", ",(0,l.kt)("em",{parentName:"p"},"ViT"),", ",(0,l.kt)("em",{parentName:"p"},"MoE"),",\nand ",(0,l.kt)("em",{parentName:"p"},"GPT"),". Feel free to customize them into different sizes to fit into your special needs."))}p.isMDXComponent=!0}}]);