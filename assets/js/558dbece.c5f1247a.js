"use strict";(self.webpackChunkdemo=self.webpackChunkdemo||[]).push([[3182],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>g});var r=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,i=function(e,t){if(null==e)return{};var n,r,i={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=r.createContext({}),p=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},c=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=i,g=d["".concat(s,".").concat(m)]||d[m]||u[m]||o;return n?r.createElement(g,a(a({ref:t},c),{},{components:n})):r.createElement(g,a({ref:t},c))}));function g(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,a=new Array(o);a[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[d]="string"==typeof e?e:i,a[1]=l;for(var p=2;p<o;p++)a[p]=n[p];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},4530:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var r=n(7462),i=(n(7294),n(3905));const o={},a="Gradient Clipping (Latest)",l={unversionedId:"features/gradient_clipping_with_booster",id:"features/gradient_clipping_with_booster",title:"Gradient Clipping (Latest)",description:"Author: Mingyan Jiang",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/features/gradient_clipping_with_booster.md",sourceDirName:"features",slug:"/features/gradient_clipping_with_booster",permalink:"/docs/features/gradient_clipping_with_booster",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/features/gradient_clipping_with_booster.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Gradient Accumulation",permalink:"/docs/features/gradient_accumulation"},next:{title:"Gradient Clipping (Outdated)",permalink:"/docs/features/gradient_clipping"}},s={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Why you should use gradient clipping provided by Colossal-AI",id:"why-you-should-use-gradient-clipping-provided-by-colossal-ai",level:2},{value:"Usage",id:"usage",level:2},{value:"Hands-On Practice",id:"hands-on-practice",level:2},{value:"step 1. Import libraries in train.py",id:"step-1-import-libraries-in-trainpy",level:3},{value:"Step 2. Initialize Distributed Environment",id:"step-2-initialize-distributed-environment",level:3},{value:"Step 3. Create training components",id:"step-3-create-training-components",level:3},{value:"Step 4. Inject Gradient Clipping Feature",id:"step-4-inject-gradient-clipping-feature",level:3},{value:"Step 5. Train with Booster",id:"step-5-train-with-booster",level:3},{value:"Step 6. Invoke Training Scripts",id:"step-6-invoke-training-scripts",level:3}],c={toc:p},d="wrapper";function u(e){let{components:t,...n}=e;return(0,i.kt)(d,(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"gradient-clipping-latest"},"Gradient Clipping (Latest)"),(0,i.kt)("p",null,"Author: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/jiangmingyan"},"Mingyan Jiang")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Prerequisite")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/basics/define_your_config"},"Define Your Configuration")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/basics/booster_api"},"Training Booster"))),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Related Paper")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1211.5063"},"On the difficulty of training Recurrent Neural Networks"))),(0,i.kt)("h2",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"In order to speed up training process and seek global optimum for better performance, more and more learning rate schedulers have been proposed. People turn to control learning rate to adjust descent pace during training, which makes gradient vector better to be uniformed in every step. In that case, the descent pace can be controlled as expected. As a result, gradient clipping, a technique which can normalize the gradient vector to circumscribe it in a uniformed length, becomes indispensable for those who desire their better performance of their models."),(0,i.kt)("p",null,"You do not have to worry about implementing gradient clipping when using Colossal-AI, we support gradient clipping in a powerful and convenient way. All you need is just an additional command in your configuration file."),(0,i.kt)("h2",{id:"why-you-should-use-gradient-clipping-provided-by-colossal-ai"},"Why you should use gradient clipping provided by Colossal-AI"),(0,i.kt)("p",null,"The reason of why we do not recommend users to write gradient clipping by themselves is that naive gradient clipping may fail when applying tensor parallelism, pipeline parallelism or MoE."),(0,i.kt)("p",null,"According to the illustration below, each GPU only owns a portion of parameters of the weight in a linear layer. To get correct norm of gradient vector of the weight of the linear layer, the norm of every gradient vector in each GPU should be summed together. More complicated thing is that the distribution of bias is different from the distribution of the weight. The communication group is different in the sum operation."),(0,i.kt)("p",null,"(PS: This situation is an old version of 2D parallelism, the implementation in the code is not the same. But it is a good example about the difficulty to unify all communication in gradient clipping.)"),(0,i.kt)("figure",{style:{textAlign:"center"}},(0,i.kt)("img",{src:"https://s2.loli.net/2022/01/28/KXiJPHt3Dum82cA.png"}),(0,i.kt)("figcaption",null,"Layout of parameters")),(0,i.kt)("p",null,"Do not worry about it, since Colossal-AI have handled it for you."),(0,i.kt)("h2",{id:"usage"},"Usage"),(0,i.kt)("p",null,"To use gradient clipping, you can just add the following code to your configuration file, and after boosted, you can call ",(0,i.kt)("inlineCode",{parentName:"p"},"clip_grad_by_norm")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"clip_grad_by_value")," method of optimizer, if it support clip gradients."),(0,i.kt)("h2",{id:"hands-on-practice"},"Hands-On Practice"),(0,i.kt)("p",null,"We now demonstrate how to use gradient clipping. In this example, we set the gradient clipping vector norm to be 1.0."),(0,i.kt)("h3",{id:"step-1-import-libraries-in-trainpy"},"step 1. Import libraries in train.py"),(0,i.kt)("p",null,"Create a ",(0,i.kt)("inlineCode",{parentName:"p"},"train.py")," and import the necessary dependencies."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import os\nfrom pathlib import Path\n\nimport torch\nfrom torchvision import transforms\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet34\nfrom tqdm import tqdm\n\nimport colossalai\nfrom colossalai.booster import Booster\nfrom colossalai.booster.plugin import TorchDDPPlugin\nfrom colossalai.logging import get_dist_logger\nfrom colossalai.nn.lr_scheduler import CosineAnnealingLR\n")),(0,i.kt)("h3",{id:"step-2-initialize-distributed-environment"},"Step 2. Initialize Distributed Environment"),(0,i.kt)("p",null,"We then need to initialize distributed environment. For demo purpose, we uses ",(0,i.kt)("inlineCode",{parentName:"p"},"launch_from_torch"),". You can refer to ",(0,i.kt)("a",{parentName:"p",href:"/docs/basics/launch_colossalai"},"Launch Colossal-AI"),"\nfor other initialization methods."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"colossalai.launch_from_torch(config=dict())\nlogger = get_dist_logger()\n")),(0,i.kt)("h3",{id:"step-3-create-training-components"},"Step 3. Create training components"),(0,i.kt)("p",null,"Build your model, optimizer, loss function, lr scheduler and dataloaders. Note that the root path of the dataset is obtained from the environment variable ",(0,i.kt)("inlineCode",{parentName:"p"},"DATA"),". You may ",(0,i.kt)("inlineCode",{parentName:"p"},"export DATA=/path/to/data")," or change ",(0,i.kt)("inlineCode",{parentName:"p"},"Path(os.environ['DATA'])")," to a path on your machine. Data will be automatically downloaded to the root path."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# define training hyperparameters\nNUM_EPOCHS = 200\nBATCH_SIZE = 128\nGRADIENT_CLIPPING = 0.1\n# build resnet\xe5\nmodel = resnet34(num_classes=10)\n# build dataloaders\ntrain_dataset = CIFAR10(root=Path(os.environ.get('DATA', './data')),\n                        download=True,\n                        transform=transforms.Compose([\n                            transforms.RandomCrop(size=32, padding=4),\n                            transforms.RandomHorizontalFlip(),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n                        ]))\n# build criterion\ncriterion = torch.nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n# lr_scheduler\nlr_scheduler = CosineAnnealingLR(optimizer, total_steps=NUM_EPOCHS)\n\n")),(0,i.kt)("h3",{id:"step-4-inject-gradient-clipping-feature"},"Step 4. Inject Gradient Clipping Feature"),(0,i.kt)("p",null,"Create a ",(0,i.kt)("inlineCode",{parentName:"p"},"TorchDDPPlugin")," object and ",(0,i.kt)("inlineCode",{parentName:"p"},"Booster")," object, get a data loader from plugin, then boost all training components."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"plugin = TorchDDPPlugin()\nbooster = Booster(mixed_precision='fp16', plugin=plugin)\ntrain_dataloader = plugin.prepare_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\nmodel, optimizer, criterion, train_dataloader, lr_scheduler = booster.boost(model,optimizer, criterion,train_dataloader, lr_scheduler)\n\n")),(0,i.kt)("h3",{id:"step-5-train-with-booster"},"Step 5. Train with Booster"),(0,i.kt)("p",null,"Use booster in a normal training loops."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# verify gradient clipping\nmodel.train()\nfor idx, (img, label) in enumerate(train_dataloader):\n    img = img.cuda()\n    label = label.cuda()\n\n    model.zero_grad()\n    output = model(img)\n    train_loss = criterion(output, label)\n    booster.backward(train_loss, optimizer)\n    optimizer.clip_grad_by_norm(max_norm=GRADIENT_CLIPPING)\n    optimizer.step()\n    lr_scheduler.step()\n\n    ele_1st = next(model.parameters()).flatten()[0]\n    logger.info(f'iteration {idx}, loss: {train_loss}, 1st element of parameters: {ele_1st.item()}')\n\n    # only run for 4 iterations\n    if idx == 3:\n        break\n")),(0,i.kt)("h3",{id:"step-6-invoke-training-scripts"},"Step 6. Invoke Training Scripts"),(0,i.kt)("p",null,"You can run the script using this command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"colossalai run --nproc_per_node 1 train.py --config config/config.py\n")))}u.isMDXComponent=!0}}]);