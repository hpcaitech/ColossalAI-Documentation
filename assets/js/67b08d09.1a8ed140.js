"use strict";(self.webpackChunkdemo=self.webpackChunkdemo||[]).push([[1155],{6999:(e,t,o)=>{o.d(t,{Cl:()=>n,Dx:()=>u,Pc:()=>i,aE:()=>l,e_:()=>p,iz:()=>a,nT:()=>c});var r=o(7294),s=o(398);o(814);function n(e){return r.createElement("div",{className:"docstring-container"},e.children)}function i(e){return r.createElement("div",{className:"signature"},"(",e.children,")")}function a(e){return r.createElement("div",{class:"divider"},r.createElement("span",{class:"divider-text"},e.name))}function l(e){return r.createElement("div",null,r.createElement(a,{name:"Parameters"}),r.createElement(s.D,null,e.children))}function c(e){return r.createElement("div",null,r.createElement(a,{name:"Returns"}),r.createElement(s.D,null,`${e.name}: ${e.desc}`))}function u(e){return r.createElement("div",{className:"title-container"},r.createElement("div",{className:"title-module"},r.createElement("h5",null,e.type),"\xa0 ",r.createElement("h3",null,e.name)),r.createElement("div",{className:"title-source"},"<",r.createElement("a",{href:e.source,className:"title-source"},"source"),">"))}function p(e){return r.createElement("div",null,r.createElement(a,{name:"Example"}),r.createElement(s.D,null,e.code))}},4511:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var r=o(7462),s=(o(7294),o(3905)),n=o(6999);const i={},a="Cluster Utilities",l={unversionedId:"features/cluster_utils",id:"features/cluster_utils",title:"Cluster Utilities",description:"Author: Hongxin Liu",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/features/cluster_utils.md",sourceDirName:"features",slug:"/features/cluster_utils",permalink:"/docs/features/cluster_utils",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/features/cluster_utils.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"NVMe offload",permalink:"/docs/features/nvme_offload"},next:{title:"Train ViT Using Pipeline Parallelism",permalink:"/docs/advanced_tutorials/train_vit_using_pipeline_parallelism"}},c={},u=[{value:"Introduction",id:"introduction",level:2},{value:"API Reference",id:"api-reference",level:2}],p={toc:u},d="wrapper";function m(e){let{components:t,...o}=e;return(0,s.kt)(d,(0,r.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"cluster-utilities"},"Cluster Utilities"),(0,s.kt)("p",null,"Author: ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/ver217"},"Hongxin Liu")),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Prerequisite:")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("a",{parentName:"li",href:"/docs/concepts/distributed_training"},"Distributed Training"))),(0,s.kt)("h2",{id:"introduction"},"Introduction"),(0,s.kt)("p",null,"We provide a utility class ",(0,s.kt)("inlineCode",{parentName:"p"},"colossalai.cluster.DistCoordinator")," to coordinate distributed training. It's useful to get various information about the cluster, such as the number of nodes, the number of processes per node, etc."),(0,s.kt)("h2",{id:"api-reference"},"API Reference"),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"class",name:"colossalai.cluster.DistCoordinator",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L11",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"*args, **kwargs"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **rank** (int) -- the rank of the current process\n- **world_size** (int) -- the total number of processes\n- **local_rank** (int) -- the rank of the current process on the current node")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"This class is used to coordinate distributed training. It is a singleton class, which means that there is only one instance of this\nclass in the whole program."),(0,s.kt)("p",null,"There are some terms that are used in this class:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"rank: the rank of the current process"),(0,s.kt)("li",{parentName:"ul"},"world size: the total number of processes"),(0,s.kt)("li",{parentName:"ul"},"local rank: the rank of the current process on the current node"),(0,s.kt)("li",{parentName:"ul"},"master: the process with rank 0"),(0,s.kt)("li",{parentName:"ul"},"node master: the process with local rank 0 on the current node")),(0,s.kt)("p",null,"Example:"),(0,s.kt)("blockquote",null,(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("p",{parentName:"blockquote"},"from colossalai.cluster.dist_coordinator import DistCoordinator\ncoordinator = DistCoordinator()"),(0,s.kt)("p",{parentName:"blockquote"},"if coordinator.is_master():\ndo_something()"),(0,s.kt)("p",{parentName:"blockquote"},"coordinator.print_on_master('hello world')"))))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"block_all",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L161",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **process_group** (ProcessGroup, optional) -- process group to block. Defaults to None, which refers to the default process group.")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Block all processes in the process group."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"destroy",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L152",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **process_group** (ProcessGroup, optional) -- process group to destroy. Defaults to None, which refers to the default process group.")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Destroy the distributed process group."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"is_last_process",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L87",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **process_group** (ProcessGroup, optional) -- process group to use for the last rank check. Defaults to None, which refers to the default process group."),(0,s.kt)(n.nT,{name:"bool",desc:"True if the current process is the last process, False otherwise",mdxType:"Returns"})),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Check if the current process is the last process (rank is world size - 1). It can accept a sub process group to check the last rank with respect to the process."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"is_master",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L64",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **process_group** (ProcessGroup, optional) -- process group to use for the rank 0 check. Defaults to None, which refers to the default process group."),(0,s.kt)(n.nT,{name:"bool",desc:"True if the current process is the master process, False otherwise",mdxType:"Returns"})),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Check if the current process is the master process (rank is 0). It can accept a sub process group to check the rank 0 with respect to the process."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"is_node_master",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L77",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},""),(0,s.kt)(n.nT,{name:"bool",desc:"True if the current process is the master process on the current node, False otherwise",mdxType:"Returns"})),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Check if the current process is the master process on the current node (local rank is 0)."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"on_master_only",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L170",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"process_group: ProcessGroup = None")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"A function wrapper that only executes the wrapped function on the master process (rank 0)."),(0,s.kt)("p",null,"Example:"),(0,s.kt)("blockquote",null,(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("p",{parentName:"blockquote"},"from colossalai.cluster import DistCoordinator\ndist_coordinator = DistCoordinator()"),(0,s.kt)("p",{parentName:"blockquote"},"@dist_coordinator.on_master_only()\ndef print_on_master(msg):\nprint(msg)")))))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"print_on_master",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L101",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"msg: str, process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **msg** (str) -- message to print\n- **process_group** (ProcessGroup, optional) -- process group to use for the rank 0 check. Defaults to None, which refers to the default process group.")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Print message only from rank 0."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"print_on_node_master",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L113",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"msg: str"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **msg** (str) -- message to print")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"Print message only from local rank 0. Local rank 0 refers to the 0th process running the current node."))),(0,s.kt)(n.Cl,{mdxType:"DocStringContainer"},(0,s.kt)("div",null,(0,s.kt)(n.Dx,{type:"function",name:"priority_execution",source:"https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/cluster/dist_coordinator.py#L124",mdxType:"Title"}),(0,s.kt)(n.Pc,{mdxType:"Signature"},"executor_rank: int = 0, process_group: ProcessGroup = None"),(0,s.kt)(n.aE,{mdxType:"Parameters"},"- **executor_rank** (int) -- the process rank to execute without blocking, all other processes will be blocked\n- **process_group** (ProcessGroup, optional) -- process group to use for the executor rank check. Defaults to None, which refers to the default process group.")),(0,s.kt)("div",null,(0,s.kt)(n.iz,{name:"Description",mdxType:"Divider"}),(0,s.kt)("p",null,"This context manager is used to allow one process to execute while blocking all\nother processes in the same process group. This is often useful when downloading is required\nas we only want to download in one process to prevent file corruption."),(0,s.kt)("p",null,"Example:"),(0,s.kt)("blockquote",null,(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("blockquote",{parentName:"blockquote"},(0,s.kt)("p",{parentName:"blockquote"},"from colossalai.cluster import DistCoordinator\ndist_coordinator = DistCoordinator()\nwith dist_coordinator.priority_execution():\ndataset = CIFAR10(root='./data', download=True)"))))))))}m.isMDXComponent=!0}}]);