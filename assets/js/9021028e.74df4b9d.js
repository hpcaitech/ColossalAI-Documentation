"use strict";(self.webpackChunkagile_docs=self.webpackChunkagile_docs||[]).push([[360],{3905:function(e,n,t){t.d(n,{Zo:function(){return u},kt:function(){return g}});var r=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,i=function(e,n){if(null==e)return{};var t,r,i={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var p=r.createContext({}),c=function(e){var n=r.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},u=function(e){var n=c(e.components);return r.createElement(p.Provider,{value:n},e.children)},s={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(e,n){var t=e.components,i=e.mdxType,a=e.originalType,p=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=c(t),g=i,m=d["".concat(p,".").concat(g)]||d[g]||s[g]||a;return t?r.createElement(m,o(o({ref:n},u),{},{components:t})):r.createElement(m,o({ref:n},u))}));function g(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var a=t.length,o=new Array(a);o[0]=d;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var c=2;c<a;c++)o[c]=t[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}d.displayName="MDXCreateElement"},8526:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return l},contentTitle:function(){return p},metadata:function(){return c},toc:function(){return u},default:function(){return d}});var r=t(3117),i=t(102),a=(t(7294),t(3905)),o=["components"],l={},p="Gradient Clipping",c={unversionedId:"features/gradient_clipping",id:"version-v0.2.2/features/gradient_clipping",title:"Gradient Clipping",description:"Author: Boxiang Wang, Haichen Huang, Yongbin Li",source:"@site/i18n/en/docusaurus-plugin-content-docs/version-v0.2.2/features/gradient_clipping.md",sourceDirName:"features",slug:"/features/gradient_clipping",permalink:"/docs/features/gradient_clipping",tags:[],version:"v0.2.2",frontMatter:{}},u=[{value:"Introduction",id:"introduction",children:[],level:2},{value:"Why you should use gradient clipping provided by Colossal-AI",id:"why-you-should-use-gradient-clipping-provided-by-colossal-ai",children:[{value:"Usage",id:"usage",children:[],level:3},{value:"Hands-On Practice",id:"hands-on-practice",children:[],level:3}],level:2}],s={toc:u};function d(e){var n=e.components,t=(0,i.Z)(e,o);return(0,a.kt)("wrapper",(0,r.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"gradient-clipping"},"Gradient Clipping"),(0,a.kt)("p",null,"Author: Boxiang Wang, Haichen Huang, Yongbin Li"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prerequisite")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"/docs/basics/define_your_config"},"Define Your Configuration")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"/docs/basics/engine_trainer"},"Use Engine and Trainer in Training"))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Example Code")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/hpcaitech/ColossalAI-Examples/tree/main/features/gradient_clipping"},"ColossalAI-Examples Gradient Clipping"))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Related Paper")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1211.5063"},"On the difficulty of training Recurrent Neural Networks"))),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"In order to speed up training process and seek global optimum for better performance, more and more learning\nrate schedulers have been proposed. People turn to control learning rate to adjust descent pace during training,\nwhich makes gradient vector better to be uniformed in every step. In that case, the descent pace can be\ncontrolled as expected. As a result, gradient clipping, a technique which can normalize the gradient vector\nto circumscribe it in a uniformed length, becomes indispensable for those who desire their better\nperformance of their models."),(0,a.kt)("p",null,"You do not have to worry about implementing gradient clipping when using Colossal-AI, we support gradient\nclipping in a powerful and convenient way. All you need is just an additional command in your configuration\nfile."),(0,a.kt)("h2",{id:"why-you-should-use-gradient-clipping-provided-by-colossal-ai"},"Why you should use gradient clipping provided by Colossal-AI"),(0,a.kt)("p",null,"The reason of why we do not recommend users to write gradient clipping by themselves is that naive gradient clipping\nmay fail when applying tensor parallelism, pipeline parallelism or MoE."),(0,a.kt)("p",null,"According to the illustration below, each GPU only owns a portion of parameters of the weight in a linear layer.\nTo get correct norm of gradient vector of the weight of the linear layer, the norm of every gradient vector in each GPU\nshould be summed together.\nMore complicated thing is that the distribution of bias is different from the distribution of the weight.\nThe communication group is different in the sum operation."),(0,a.kt)("p",null,"(PS: This situation is an old version of 2D parallelism, the implementation in the code is not the same.\nBut it is a good example about the difficulty to unify all communication in gradient clipping.)"),(0,a.kt)("figure",{style:{textAlign:"center"}},(0,a.kt)("img",{src:"https://s2.loli.net/2022/01/28/KXiJPHt3Dum82cA.png"}),(0,a.kt)("figcaption",null,"Layout of parameters")),(0,a.kt)("p",null,"Do not worry about it, since Colossal-AI have handled it for you."),(0,a.kt)("h3",{id:"usage"},"Usage"),(0,a.kt)("p",null,"To use gradient clipping, you can just simply add gradient clipping norm in your configuration file."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"clip_grad_norm = 1.0\n")),(0,a.kt)("h3",{id:"hands-on-practice"},"Hands-On Practice"),(0,a.kt)("p",null,"We provide a ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/hpcaitech/ColossalAI-Examples/tree/main/features/gradient_clipping"},"runnable example"),"\nto demonstrate gradient clipping. In this example, we set the gradient clipping vector norm to be 1.0. You can run the script using this command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"python -m torch.distributed.launch --nproc_per_node 1 --master_addr localhost --master_port 29500  train_with_engine.py\n")))}d.isMDXComponent=!0}}]);