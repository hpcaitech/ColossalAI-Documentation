"use strict";(self.webpackChunkdemo=self.webpackChunkdemo||[]).push([[3206],{3905:(e,t,r)=>{r.d(t,{Zo:()=>u,kt:()=>f});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var s=n.createContext({}),d=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},u=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},p="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=d(r),m=o,f=p["".concat(s,".").concat(m)]||p[m]||c[m]||a;return r?n.createElement(f,l(l({ref:t},u),{},{components:r})):n.createElement(f,l({ref:t},u))}));function f(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,l=new Array(a);l[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[p]="string"==typeof e?e:o,l[1]=i;for(var d=2;d<a;d++)l[d]=r[d];return n.createElement.apply(null,l)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},6984:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>c,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var n=r(7462),o=(r(7294),r(3905));const a={},l="Define your own parallel model",i={unversionedId:"advanced_tutorials/define_your_own_parallel_model",id:"advanced_tutorials/define_your_own_parallel_model",title:"Define your own parallel model",description:"Author: Zhengda Bian, Yongbin Li",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/advanced_tutorials/define_your_own_parallel_model.md",sourceDirName:"advanced_tutorials",slug:"/advanced_tutorials/define_your_own_parallel_model",permalink:"/docs/advanced_tutorials/define_your_own_parallel_model",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/advanced_tutorials/define_your_own_parallel_model.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Train GPT Using Hybrid Parallelism",permalink:"/docs/advanced_tutorials/train_gpt_using_hybrid_parallelism"},next:{title:"Add Your Own Parallel Mode",permalink:"/docs/advanced_tutorials/add_your_parallel"}},s={},d=[{value:"Write a simple 2D parallel model",id:"write-a-simple-2d-parallel-model",level:2},{value:"Use pre-defined model",id:"use-pre-defined-model",level:2}],u={toc:d},p="wrapper";function c(e){let{components:t,...r}=e;return(0,o.kt)(p,(0,n.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"define-your-own-parallel-model"},"Define your own parallel model"),(0,o.kt)("p",null,"Author: Zhengda Bian, Yongbin Li"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"\u26a0\ufe0f We are working on this documentation to make it more detailed. We will introduce the mechanism of different parallelism\nand how to use them to write a model.")),(0,o.kt)("p",null,"Let's say that you have a huge MLP model with billions of parameters and its extremely large hidden layer size makes it\nimpossible to fit into a single GPU directly. Don't worry, Colossal-AI is here to help you sort things out. With the help of Colossal-AI,\nyou can write your model in the familiar way in which you used to write models for a single GPU, while Colossal-AI automatically\nsplits your model weights and fit them perfectly into a set of GPUs. We give a simple example showing how to write a simple\n2D parallel model in the Colossal-AI context."),(0,o.kt)("h2",{id:"write-a-simple-2d-parallel-model"},"Write a simple 2D parallel model"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from colossalai.nn import Linear2D\nimport torch.nn as nn\n\nclass MLP_2D(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.linear_1 = Linear2D(in_features=1024, out_features=16384)\n        self.linear_2 = Linear2D(in_features=16384, out_features=1024)\n\n    def forward(self, x):\n        x = self.linear_1(x)\n        x = self.linear_2(x)\n        return x\n")),(0,o.kt)("h2",{id:"use-pre-defined-model"},"Use pre-defined model"),(0,o.kt)("p",null,"For the sake of your convenience, we kindly provide you in our Model Zoo with some prevalent models such as ",(0,o.kt)("em",{parentName:"p"},"BERT"),", ",(0,o.kt)("em",{parentName:"p"},"ViT"),", ",(0,o.kt)("em",{parentName:"p"},"MoE"),",\nand ",(0,o.kt)("em",{parentName:"p"},"GPT"),". Feel free to customize them into different sizes to fit into your special needs."))}c.isMDXComponent=!0}}]);